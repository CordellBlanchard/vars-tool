{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "965cc71f-c5e9-4c62-b596-29ed91199872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stat\n",
    "from scipy.optimize import newton_krylov\n",
    "from scipy.integrate import dblquad\n",
    "from itertools import combinations, chain, repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "993d8e78-2fe0-481f-a6da-1d391d764910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_additive(x):\n",
    "    term1 = 2*x[0]\n",
    "    term2 = 3*x[1]\n",
    "    return term1 + term2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58b8067c-ab82-41f8-9156-f24850ef4ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rx2rn(distpair_type, param1, param2, rxpair):\n",
    "    \n",
    "    # getting the inverse cdf of distribution 1\n",
    "    if (distpair_type[0] == 'unif'):\n",
    "        mu1 = (param1[1] + param1[0])/2\n",
    "        std1 = (param1[1] - param1[0])/12**0.5\n",
    "        inv_cdf1 = lambda x : param1[0] + (param1[1] - param1[0])*x\n",
    "    elif (distpair_type[0] == 'norm'):\n",
    "        mu1 = param1[0]\n",
    "        std1 = param1[1]\n",
    "        inv_cdf1 = lambda x : stat.norm.ppf(x, mu1, std1)\n",
    "    elif (distpair_type[0] == 'triangle'):\n",
    "        mu1 = (param1[0] + param1[1] + param1[2])/3\n",
    "        std1 = (np.sqrt(param1[0]**2+param1[1]**2+param1[2]**2-param1[0]*param1[1]-param1[0]*param1[2]-param1[1]*param1[2]))/np.sqrt(18)\n",
    "        mid1=(param1[2]-param1[0])/(param1[1]-param1[0])\n",
    "        term11= (param1[1]-param1[0])*(param1[2]-param1[0])\n",
    "        term21= (param1[1]-param[0])*(param1[1]-param1[2])\n",
    "        inv_cdf1 = lambda x : ((param1[0]+np.sqrt(term11)*np.sqrt(x/1))*((x>=0).astype(int))*((x<mid1).astype(int)) + (param1[1]-np.sqrt(term21)*np.sqrt(1-x))*((x>=mid1).astype(int))*((x<1).astype(int)))\n",
    "    elif (distpair_type[0] == 'lognorm'):\n",
    "        mu1= param1[0]\n",
    "        std1=param1[1]\n",
    "        # compute associated normal\n",
    "        cv=std1/mu1**2\n",
    "        m = np.log(mu1/(np.sqrt(1+cv)))\n",
    "        v = np.sqrt(np.log(1+cv))           \n",
    "        inv_cdf1 = lambda x : stat.lognorm.ppf(x, scale=np.exp(m), s=v, loc=0)\n",
    "    elif (distpair_type[0] == 'expo'):\n",
    "        lamda= param1[0]\n",
    "        mu1=1/lamda\n",
    "        std1=1/(lamda**2)\n",
    "        inv_cdf1 = lambda x : stat.expon.ppf(x, scale=mu1)\n",
    "    elif (distpair_type[0] == 'gev'):\n",
    "        mu=param1[0] #location\n",
    "        sigma=param1[1] #scale\n",
    "        k1=param1[2] #shape\n",
    "        inv_cdf1 = lambda x : stat.genextreme.ppf(x,c=k1,scale=sigma,loc=mu);\n",
    "        [mu1,std1] = stat.genextreme.stats(k1,scale=sigma,loc=mu);\n",
    "        \n",
    "    # getting the inverse cdf of distribution 2\n",
    "    if (distpair_type[1] == 'unif'):\n",
    "        mu2 = (param2[1] + param2[0])/2\n",
    "        std2 = (param2[1] - param2[0])/12**0.5\n",
    "        inv_cdf2 = lambda x : param2[0] + (param2[1] - param2[0])*x\n",
    "    elif (distpair_type[1] == 'norm'):\n",
    "        mu2 = param2[0]\n",
    "        std2 = param2[1]\n",
    "        inv_cdf2 = lambda x : stat.norm.ppf(x, mu2, std2)\n",
    "    elif (distpair_type[1] == 'triangle'):\n",
    "        mu2 = (param2[0] + param2[1] + param2[2])/3\n",
    "        std2 = (np.sqrt(param2[0]**2+param2[1]**2+param2[2]**2-param2[0]*param2[1]-param2[0]*param2[2]-param2[1]*param2[2]))/np.sqrt(18)\n",
    "        mid2=(param2[2]-param2[0])/(param2[1]-param2[0])\n",
    "        term12= (param2[1]-param2[0])*(param2[2]-param2[0])\n",
    "        term22= (param2[1]-param2[0])*(param2[1]-param2[2])\n",
    "        inv_cdf2 = lambda x : ((param2[0]+np.sqrt(term12)*np.sqrt(x/1))*((x>=0).astype(int))*((x<mid2).astype(int)) + (param2[1]-np.sqrt(term22)*np.sqrt(1-x))*((x>=mid1).astype(int))*((x<1).astype(int)))\n",
    "    elif (distpair_type[1] == 'lognorm'):\n",
    "        mu2= param2[0]\n",
    "        std2=param2[1]\n",
    "        # compute associated normal\n",
    "        cv=std2/mu2**2\n",
    "        m = np.log(mu2/(np.sqrt(1+cv)))\n",
    "        v = np.sqrt(np.log(1+cv))           \n",
    "        inv_cdf2 = lambda x : stat.lognorm.ppf(x, scale=np.exp(m), s=v, loc=0)\n",
    "    elif (distpair_type[1] == 'expo'):\n",
    "        lamda= param2[0]\n",
    "        mu2=1/lamda\n",
    "        std2=1/(lamda**2)\n",
    "        inv_cdf2 = lambda x : stat.expon.ppf(x, scale=mu2)\n",
    "    elif (distpair_type[1] == 'gev'):\n",
    "        mu=param2[0] #location\n",
    "        sigma=param2[1] #scale\n",
    "        k2=param2[2] #shape\n",
    "        inv_cdf2 = lambda x : stat.genextreme.ppf(x,c=k2,scale=sigma,loc=mu);\n",
    "        [mu2,std2] = stat.genextreme.stats(k2,scale=sigma,loc=mu);\n",
    "    \n",
    "    # bivariate standard normal distribution\n",
    "    stdnorm2_pdf = lambda x1, x2 : np.exp(-1*(x1**2 + x2**2)/2.0)/(2.0*np.pi)\n",
    "    \n",
    "    # integral bound zmax=5.0, zmin = -5.0\n",
    "    integrand = lambda x1, x2 : inv_cdf1(stat.norm.cdf(x1*np.sqrt(1-rxpair**2)+ rxpair*x2,0,1))*inv_cdf2(stat.norm.cdf(x2,0,1))*stdnorm2_pdf(x1, x2)\n",
    "    # compute double integral of integrand with x1 ranging from -5.0 to 5.0 and x2 ranging from -5.0 to 5.0\n",
    "    rn = (dblquad(integrand, -5.0, 5.0, lambda x : -5.0, lambda x : 5.0) - mu1*mu2)/(std1*std2)\n",
    "    \n",
    "    return rn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e915ce16-5f60-4286-9cfe-74e0d8f9e4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rn2rx(distpair_type, param1, param2, rnpair):    \n",
    "    fun = lambda r : (rnpair - rx2rn(distpair_type, param1, param2, r))\n",
    "    # try to find point x where fun(x) = 0\n",
    "    try:\n",
    "        rx = newton_krylov(fun, rnpair, x_tol=1e-5)\n",
    "    except:\n",
    "        rx = rnpair\n",
    "            \n",
    "    return rx    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7130e67-255f-457e-b9c6-7c2d055e0930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_2_cornorm(parameters, corr_mat):\n",
    "    # store parameter info in a list\n",
    "    param_info = list(parameters.values())\n",
    "    \n",
    "    corr_n = np.eye(corr_mat.shape[0], corr_mat.shape[1])\n",
    "    for i in range(0, corr_mat.shape[0] - 1):\n",
    "        for j in range(i+1, corr_mat.shape[0]):\n",
    "            # input paramter info (lb, ub, ?, dist type)\n",
    "            corr_n[i][j] = rn2rx([param_info[i][3], param_info[j][3]], [param_info[i][0], param_info[i][1], param_info[i][2]],[param_info[j][0], param_info[j][1], param_info[j][2]],corr_mat[i][j])\n",
    "            # matrix is symmetrical\n",
    "            corr_n[j][i] = corr_n[i][j]\n",
    "    return corr_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bad9f51-b1e7-4d41-85b9-482766efa263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n2x_transform(norm_vectors, parameters):\n",
    "    # Transform from correlated standard normal to original distributions\n",
    "    param_info = list(parameters.values())\n",
    "    \n",
    "    # \n",
    "    k = norm_vectors.shape[1]   \n",
    "    x = np.zeros(norm_vectors.shape)\n",
    "\n",
    "    for i in range(0, k):\n",
    "        if param_info[i][3] == 'unif':\n",
    "            lb = param_info[i][0]\n",
    "            ub = param_info[i][1]\n",
    "\n",
    "            x[:, i] = lb + (ub - lb)*stat.norm.cdf(norm_vectors[:, i],0,1)\n",
    "        elif param_info[i][3] == 'norm':\n",
    "            mu = param_info[i][0]\n",
    "            std = param_info[i][1]\n",
    "\n",
    "            x[:, i] = stat.norm.ppf(stat.norm.cdf(norm_vectors[:, i],0,1), mu, std)\n",
    "        elif param_info[i][3] == 'triangle':\n",
    "            a = param_info[i][0]\n",
    "            b = param_info[i][1]\n",
    "            c = param_info[i][2]\n",
    "            mid = (c-a)/(b-a)\n",
    "            term1 = (b-a)*(c-a)\n",
    "            term2 = (b-a)*(b-c)\n",
    "            x_norm = stat.norm.cdf(norm_vector[:, i],0,1)\n",
    "            x[:, i] = (a+np.sqrt(term1)*np.sqrt(x_norm))*((x_norm >= 0).astype(int))*((x_norm < mid).astype(int))+(b-np.sqrt(term2)*np.sqrt((1-x_norm)))*((x_norm >= mid).astype(int))*((x_norm < 1).astype(int))\n",
    "        elif param_info[i][3] == 'lognorm':\n",
    "            mu = param_info[i][0]\n",
    "            std = param_info[i][1]\n",
    "            term1 = std/mu**2\n",
    "            m = np.log(mu/(np.sqrt(1+term1)))\n",
    "            v = np.sqrt(np.log(1+term1))\n",
    "            x[:, i] = np.lognorm.ppf(stat.norm.cdf(norm_vectors[:, i],0,1), scale=np.exp(mu), s=std, loc=0)\n",
    "        elif param_info[i][3] == 'expo':\n",
    "            mu = param_info[i][0]\n",
    "            x[:, i] = np.expon.ppf(stat.norm.cdf(norm_vectors[:, i],0,1), scale=mu)\n",
    "        elif param_info[i][3] == 'gev':\n",
    "            mu = param_info[i][0] # location\n",
    "            sigma = param_info[i][1] # scale\n",
    "            k = param_info[i][2] # shape\n",
    "            x[:, i] = stat.genextreme.ppf(stat.norm.cdf(norm_vectors[:, i],0,1),c=k,scale=sigma,loc=mu)\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c69bdf9-a8fa-4ed3-8291-a217af723c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GVARS inputs\n",
    "seed = 12345678\n",
    "num_stars = 10\n",
    "num_dir_samples = 50\n",
    "delta_h = 0.1\n",
    "ivars_scales = [0.1, 0.3, 0.5]\n",
    "parameters = {'x1' : (0, 1, None, 'norm'),\n",
    "              'x2' : (0, 1, None, 'norm')}\n",
    "corr_mat = np.array([[1, 0.6], [0.6, 1]])\n",
    "n_var = len(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32b8ddd4-5795-4d80-a3d6-59c8d4c7bd27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 0.6],\n",
       "       [0.6, 1. ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_mat = map_2_cornorm(parameters, corr_mat)\n",
    "cov_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ece33a3-9933-4526-a4d5-a04cef976a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04188231, -1.43650834],\n",
       "       [-2.37744837,  0.77764303],\n",
       "       [-1.10330162, -2.02919731],\n",
       "       [-1.16747121,  0.1087427 ],\n",
       "       [ 0.43522013,  0.30987233],\n",
       "       [ 2.17770596,  0.58895914],\n",
       "       [-0.1934313 ,  1.12429862],\n",
       "       [ 0.90325226, -0.30493676],\n",
       "       [-0.21358142, -0.94669055],\n",
       "       [ 0.06661068,  1.17500076]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate independent standard normal samples\n",
    "# the amount of samples is the same as the amount of stars\n",
    "U = np.random.multivariate_normal(np.zeros(n_var), np.eye(n_var), num_stars)\n",
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba47dd74-d3c7-49b8-9b98-6a242c4d6623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04188231, -1.12407728],\n",
       "       [-2.37744837, -0.8043546 ],\n",
       "       [-1.10330162, -2.28533882],\n",
       "       [-1.16747121, -0.61348857],\n",
       "       [ 0.43522013,  0.50902995],\n",
       "       [ 2.17770596,  1.77779089],\n",
       "       [-0.1934313 ,  0.78338012],\n",
       "       [ 0.90325226,  0.29800195],\n",
       "       [-0.21358142, -0.88550129],\n",
       "       [ 0.06661068,  0.97996701]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate correlated standard normal samples\n",
    "# the amount of samples is the same as the amount of stars\n",
    "cholU = np.linalg.cholesky(cov_mat)\n",
    "cholU = cholU.transpose() # to get in correct format for matrix multiplication\n",
    "Z = np.matmul(U,cholU) # transform samples to standard normal distribution\n",
    "display(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f868e7f9-4b2a-4839-8475-e5d20983e5da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04188231, -1.12407728],\n",
       "       [-2.37744837, -0.8043546 ],\n",
       "       [-1.10330162, -2.28533882],\n",
       "       [-1.16747121, -0.61348857],\n",
       "       [ 0.43522013,  0.50902995],\n",
       "       [ 2.17770596,  1.77779089],\n",
       "       [-0.1934313 ,  0.78338012],\n",
       "       [ 0.90325226,  0.29800195],\n",
       "       [-0.21358142, -0.88550129],\n",
       "       [ 0.06661068,  0.97996701]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate Nstar actual multivariate samples X\n",
    "X = n2x_transform(Z, parameters)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2230473-12d9-44d0-ac79-ae93375fd8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define index matrix of complement subset\n",
    "compsub = np.empty([n_var, n_var-1])\n",
    "for i in range (0, n_var):\n",
    "\n",
    "    temp = np.arange(n_var)\n",
    "    compsub[i] = np.delete(temp, i)   \n",
    "compsub = compsub.astype(int)\n",
    "compsub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d461e084-e2de-4c2f-bff8-1544104e6d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computer coditional variance and conditional expectation for each star center\n",
    "chol_cond_std = []\n",
    "std_cond_norm = []\n",
    "mui_on_noti = np.zeros((len(Z), n_var))\n",
    "for i in range(0, n_var):\n",
    "    noti = compsub[i]\n",
    "    # 2 dimensional or greater matrix case\n",
    "    if (cov_mat[noti, noti].ndim >= 2):\n",
    "        cond_std = cov_mat[i][i] - cov_mat[i,noti]*np.linalg.inv(cov_mat[noti, noti])*cov_mat[noti,i]\n",
    "        chol_cond_std.append(np.linalg.cholesky(cond_std))\n",
    "        std_cond_norm.append(con_std)\n",
    "        for j in range(0, len(Z)):\n",
    "            mui_on_noti[j][i] = cov_mat[i,noti]*np.linalg.inv(cov_mat[noti, noti])*Z[j,noti]\n",
    "    # less then 2 dimenional matrix case\n",
    "    else:\n",
    "        cond_std = cov_mat[i][i] - cov_mat[i,noti]*cov_mat[noti, noti]*cov_mat[noti,i]\n",
    "        chol_cond_std.append(np.linalg.cholesky([[cond_std]]).flatten())\n",
    "        std_cond_norm.append(cond_std)\n",
    "        for j in range(0, len(Z)):\n",
    "            mui_on_noti[j][i] = cov_mat[i, noti]*cov_mat[noti, noti]*Z[j, noti]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3dc2d686-e7aa-4cd2-8613-c3eb42f0ac98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 2, 10)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate directional sample:\n",
    "# Create samples in correlated standard normal space\n",
    "all_section_condZ = []\n",
    "condZ = []\n",
    "for j in range(0, num_dir_samples):\n",
    "    stnrm_base = np.random.multivariate_normal(np.zeros(n_var), np.eye(n_var), num_stars)\n",
    "    for i in range(0, n_var):\n",
    "        condZ.append(stnrm_base[:, i]*chol_cond_std[i] + mui_on_noti[:, i])\n",
    "    all_section_condZ.append(condZ.copy())\n",
    "    condZ.clear()\n",
    "    \n",
    "np.array(all_section_condZ).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "82def3cd-1173-4d7b-9b5f-8880f9bf6acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 2, 10)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform to original distribution and compute response surface\n",
    "Xi_on_Xnoti = []\n",
    "tmp1 = []\n",
    "Xi_on_Xnoti_and_Xnoti_temp = []\n",
    "Xi_on_Xnoti_and_Xnoti = []\n",
    "for j in range(0, num_dir_samples):\n",
    "    for i in range(0, len(parameters)):\n",
    "        tmp1.append(n2x_transform(np.array([all_section_condZ[j][i]]).transpose(), parameters).flatten())\n",
    "        tmp2 = X.copy()\n",
    "        tmp2[:, i] = tmp1[i]\n",
    "        Xi_on_Xnoti_and_Xnoti_temp.append(tmp2.copy()) \n",
    "    # attatch results from tmp1 onto Xi_on_Xnoti and Xi_on_Xnoti_and_Xnoti\n",
    "    Xi_on_Xnoti.append(tmp1.copy())\n",
    "    tmp1.clear() # clear for next iteration\n",
    "    Xi_on_Xnoti_and_Xnoti.append(Xi_on_Xnoti_and_Xnoti_temp.copy())\n",
    "    Xi_on_Xnoti_and_Xnoti_temp.clear() # clear for next iteration\n",
    "        \n",
    "np.array(Xi_on_Xnoti).shape # check that shape is the same as all_section condZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9ca0e96a-49d4-40b6-8a83-d8059babd566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Star points\n",
    "params = [*parameters]\n",
    "star_points = {}\n",
    "points = {}\n",
    "temp = np.zeros([num_dir_samples, len(parameters)])\n",
    "for i in range(0, num_stars):\n",
    "    for j in range(0, len(parameters)):\n",
    "        for k in range(0, num_dir_samples):\n",
    "            temp[k, :] = Xi_on_Xnoti_and_Xnoti[k][j][i]\n",
    "        points[params[j]] = np.copy(temp)\n",
    "    star_points[i] = points.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9d0ac6b2-fdc6-4ca2-905d-a398471f4837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>centre</th>\n",
       "      <th>param</th>\n",
       "      <th>points</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">x1</th>\n",
       "      <th>0</th>\n",
       "      <td>-0.368952</td>\n",
       "      <td>-1.124077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.795732</td>\n",
       "      <td>-1.124077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.570933</td>\n",
       "      <td>-1.124077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.315725</td>\n",
       "      <td>-1.124077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.157375</td>\n",
       "      <td>-1.124077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">9</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">x2</th>\n",
       "      <th>45</th>\n",
       "      <td>0.066611</td>\n",
       "      <td>0.663996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.066611</td>\n",
       "      <td>-0.649220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.066611</td>\n",
       "      <td>-0.766905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.066611</td>\n",
       "      <td>-0.504398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.066611</td>\n",
       "      <td>1.446239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0         1\n",
       "centre param points                    \n",
       "0      x1    0      -0.368952 -1.124077\n",
       "             1      -0.795732 -1.124077\n",
       "             2      -0.570933 -1.124077\n",
       "             3      -0.315725 -1.124077\n",
       "             4      -1.157375 -1.124077\n",
       "...                       ...       ...\n",
       "9      x2    45      0.066611  0.663996\n",
       "             46      0.066611 -0.649220\n",
       "             47      0.066611 -0.766905\n",
       "             48      0.066611 -0.504398\n",
       "             49      0.066611  1.446239\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "star_points_df = pd.concat({key: pd.concat({k: pd.DataFrame(d) for k, d in value.items()}) for key, value in star_points.items()})\n",
    "star_points_df.index.names=['centre', 'param', 'points']\n",
    "star_points_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4436064d-4fe2-4b39-9fe1-914ef0c66429",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-81-2b471e26cf18>:1: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "def apply_unique(func, df, axis=1, *args, **kwargs):\n",
    "    '''Apply a function to unique rows of a DataFrame\n",
    "    for efficiency.'''\n",
    "    \n",
    "    tqdm.pandas(desc=func.__name__ + ' evaluation')\n",
    "\n",
    "    applied_df = df.merge(df.drop_duplicates()\n",
    "                         .assign(**{func.__name__: lambda x: x.progress_apply(func, axis=axis)}), \n",
    "                         how='left')\n",
    "    applied_df.index = df.index\n",
    "    \n",
    "    return applied_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c3e733e7-03e7-48bd-96ec-954abcc7e1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33aefce85ff540c0a135fe6fbaac6d30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "linear_additive evaluation:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>linear_additive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>centre</th>\n",
       "      <th>param</th>\n",
       "      <th>points</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">x1</th>\n",
       "      <th>0</th>\n",
       "      <td>-0.368952</td>\n",
       "      <td>-1.124077</td>\n",
       "      <td>-4.110137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.795732</td>\n",
       "      <td>-1.124077</td>\n",
       "      <td>-4.963695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.570933</td>\n",
       "      <td>-1.124077</td>\n",
       "      <td>-4.514097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.315725</td>\n",
       "      <td>-1.124077</td>\n",
       "      <td>-4.003683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.157375</td>\n",
       "      <td>-1.124077</td>\n",
       "      <td>-5.686982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">9</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">x2</th>\n",
       "      <th>45</th>\n",
       "      <td>0.066611</td>\n",
       "      <td>0.663996</td>\n",
       "      <td>2.125209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.066611</td>\n",
       "      <td>-0.649220</td>\n",
       "      <td>-1.814440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.066611</td>\n",
       "      <td>-0.766905</td>\n",
       "      <td>-2.167495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.066611</td>\n",
       "      <td>-0.504398</td>\n",
       "      <td>-1.379974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.066611</td>\n",
       "      <td>1.446239</td>\n",
       "      <td>4.471940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0         1  linear_additive\n",
       "centre param points                                     \n",
       "0      x1    0      -0.368952 -1.124077        -4.110137\n",
       "             1      -0.795732 -1.124077        -4.963695\n",
       "             2      -0.570933 -1.124077        -4.514097\n",
       "             3      -0.315725 -1.124077        -4.003683\n",
       "             4      -1.157375 -1.124077        -5.686982\n",
       "...                       ...       ...              ...\n",
       "9      x2    45      0.066611  0.663996         2.125209\n",
       "             46      0.066611 -0.649220        -1.814440\n",
       "             47      0.066611 -0.766905        -2.167495\n",
       "             48      0.066611 -0.504398        -1.379974\n",
       "             49      0.066611  1.446239         4.471940\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = linear_additive\n",
    "df = apply_unique(model_name, star_points_df, axis=1)\n",
    "df.index.names=['centre', 'param', 'points']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0eea66ae-1734-4b0b-ba34-f86ece823eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2554b56cbc654011960c1682858b0ebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "building pairs:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>centre</th>\n",
       "      <th>param</th>\n",
       "      <th>h</th>\n",
       "      <th>pair_ind</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">x1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.1</th>\n",
       "      <th>(0, 1)</th>\n",
       "      <td>-4.110137</td>\n",
       "      <td>-4.963695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(1, 2)</th>\n",
       "      <td>-4.963695</td>\n",
       "      <td>-4.514097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(2, 3)</th>\n",
       "      <td>-4.514097</td>\n",
       "      <td>-4.003683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(3, 4)</th>\n",
       "      <td>-4.003683</td>\n",
       "      <td>-5.686982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(4, 5)</th>\n",
       "      <td>-5.686982</td>\n",
       "      <td>-5.402377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">9</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">x2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">4.7</th>\n",
       "      <th>(1, 48)</th>\n",
       "      <td>-2.456485</td>\n",
       "      <td>-1.379974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(2, 49)</th>\n",
       "      <td>0.508859</td>\n",
       "      <td>4.471940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4.8</th>\n",
       "      <th>(0, 48)</th>\n",
       "      <td>-1.032056</td>\n",
       "      <td>-1.379974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(1, 49)</th>\n",
       "      <td>-2.456485</td>\n",
       "      <td>4.471940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.9</th>\n",
       "      <th>(0, 49)</th>\n",
       "      <td>-1.032056</td>\n",
       "      <td>4.471940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  0         1\n",
       "centre param h   pair_ind                    \n",
       "0      x1    0.1 (0, 1)   -4.110137 -4.963695\n",
       "                 (1, 2)   -4.963695 -4.514097\n",
       "                 (2, 3)   -4.514097 -4.003683\n",
       "                 (3, 4)   -4.003683 -5.686982\n",
       "                 (4, 5)   -5.686982 -5.402377\n",
       "...                             ...       ...\n",
       "9      x2    4.7 (1, 48)  -2.456485 -1.379974\n",
       "                 (2, 49)   0.508859  4.471940\n",
       "             4.8 (0, 48)  -1.032056 -1.379974\n",
       "                 (1, 49)  -2.456485  4.471940\n",
       "             4.9 (0, 49)  -1.032056  4.471940\n",
       "\n",
       "[24500 rows x 2 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the paired values of each section based on `h`\n",
    "tqdm.pandas(desc='building pairs')\n",
    "\n",
    "pair_df = df[model_name.__name__].groupby(level=[0,1]).progress_apply(section_df, delta_h=delta_h)\n",
    "pair_df.index.names = ['centre', 'param', 'h', 'pair_ind']\n",
    "pair_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ac42ffa3-3b94-4f55-936b-f1438bad1068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def apply_unique(func, df, axis=1, *args, **kwargs):\n",
    "    '''Apply a function to unique rows of a DataFrame\n",
    "    for efficiency.'''\n",
    "\n",
    "    applied_df = df.merge(df.drop_duplicates()\n",
    "                         .assign(**{func.__name__: lambda x: x.apply(func, axis=axis)}), \n",
    "                         how='left')\n",
    "    applied_df.index = df.index\n",
    "    \n",
    "    return applied_df\n",
    "    \n",
    "    \n",
    "def scale(df, bounds, axis=1, *args, **kwargs):\n",
    "    '''scale the sampled matrix\n",
    "    bounds is a dict with ['ub', 'lb'] keys\n",
    "    the values are lists of the upper and lower bounds\n",
    "    of the parameters/variables/factors'''\n",
    "    \n",
    "    # numpy equivalent for math operations\n",
    "    bounds_np = {key:np.array(value) for key,value in bounds.items()}\n",
    "    \n",
    "    if axis:\n",
    "        return df * (bounds_np['ub'] - bounds_np['lb']) + bounds_np['lb']\n",
    "    else:\n",
    "        return df.T * (bounds_np['ub'] - bounds_np['lb']) + bounds_np['lb']\n",
    "    \n",
    "    \n",
    "def pairs_h(iterable):\n",
    "    '''gives the pairs of numbers considering their differences'''\n",
    "    interval = range(min(iterable), max(iterable)-min(iterable))\n",
    "    pairs  = {key+1:[j for j in combinations(iterable, 2) if np.abs(j[0]-j[1])==key+1] for key in interval}\n",
    "    return pairs\n",
    "    \n",
    "    \n",
    "def section_df(df, delta_h): # ***delta_h here is newly added*** July 6th, 2021 - Saman's comment\n",
    "    '''gets the paired values of each section based on index'''\n",
    "    pairs = pairs_h(df.index.get_level_values(-1))\n",
    "    df_values = df.to_numpy()\n",
    "    sample = pd.concat({h*delta_h:\n",
    "                    pd.DataFrame.from_dict({str(idx_tup): [df_values[idx_tup[0]], df_values[idx_tup[1]]] for idx_tup in idx}, 'index') \\\n",
    "                      for h, idx in pairs.items()}) \n",
    "\n",
    "    return sample\n",
    "    \n",
    "    \n",
    "# lambda functions\n",
    "'''covariogram of each section'''\n",
    "cov_section = lambda pair_cols, mu_star: (pair_cols.sub(mu_star, axis=0)[0] * pair_cols.sub(mu_star, axis=0)[1]).groupby(level=[0,1,2]).mean()\n",
    "\n",
    "'''variogram over all sections'''\n",
    "variogram = lambda pair_cols: 0.5*(pair_cols[0] - pair_cols[1]).pow(2).groupby(level=[1,2]).mean()\n",
    "\n",
    "'''morris sensitivity measure equivalent evaluated over all sections'''\n",
    "morris_eq = lambda pair_cols: ((pair_cols[1] - pair_cols[0]).abs().groupby(level=[1,2]).mean(), \\\n",
    "                               (pair_cols[1] - pair_cols[0]).groupby(level=[1,2]).mean())\n",
    "\n",
    "'''covariogram over all sections'''\n",
    "covariogram = lambda pair_cols, mu_overall: ((pair_cols - mu_overall)[0] * (pair_cols - mu_overall)[1]).groupby(level=[1,2]).mean()\n",
    "\n",
    "'''expected covariogram over all sections'''\n",
    "e_covariogram = lambda cov_section_all: cov_section_all.groupby(level=[1,2]).mean()\n",
    "\n",
    "'''sobol (total order) sensitivity measure equivalent evaluated over all sections''' # new sobol added *** 6 July 2021\n",
    "# sobol_eq = lambda gamma, ecov, variance: ((gamma + ecov) / variance).loc[:,1]\n",
    "sobol_eq = lambda gamma, ecov, variance, delta_h: ((gamma + ecov) / variance)[:, delta_h] # new July 6, 2021\n",
    "\n",
    "\n",
    "\n",
    "# ivars function\n",
    "def ivars(variogram_array, scale, delta_h):\n",
    "    '''generate Integrated Variogram Across a Range of Scales (IVARS)\n",
    "    by approximating area using right trapezoids having width of `delta_h`\n",
    "    and hights of variogram values'''\n",
    "    num_h  = len(variogram_value.index.levels[-1].to_list())\n",
    "    x_bench= np.arange(start=0, stop=delta_h*(num_h+1), step=delta_h)\n",
    "    x_int  = np.arange(start=0, stop=(scale*10+1)/10, step=delta_h)\n",
    "\n",
    "    # calculate interpolated values for both x (h) and y (variogram)\n",
    "    if x_int[-1] < scale:\n",
    "        x_int.append(scale)\n",
    "    y_bench= [0] + variogram_array.to_list()\n",
    "\n",
    "    y_int  = np.interp(x=x_int, xp=x_bench, fp=y_bench)\n",
    "    \n",
    "    # for loop for each step size to caluclate the area\n",
    "    ivars = 0\n",
    "    for i in range(len(x_int)-1):\n",
    "        ivars += 0.5*(y_int[i+1] + y_int[i]) * (x_int[i+1] - x_int[i])\n",
    "\n",
    "    return ivars\n",
    "\n",
    "# alias\n",
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea50e632-61d7-42bd-b413-277241a501fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
