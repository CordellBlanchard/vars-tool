{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Tuple\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _greedy_plhs(sp:int, slices:int, sample:np.array) -> Tuple[np.array, np.array, float, float]:\n",
    "    '''\n",
    "    Description:\n",
    "    ------------\n",
    "    Generates a Progressive Latin Hypercube Sampling (PLHS) from\n",
    "    an optimal Sliced Lating Hypercube Sampling design (SLHS) \n",
    "    using a greedy algorithm; based on [1] and [2]\n",
    "\n",
    "\n",
    "    Arguments:\n",
    "    ----------\n",
    "    :param sp: number of sample points\n",
    "    :type sp: int, np.int32, or np.int64\n",
    "    :param slices: number of slices\n",
    "    :type slices: int, np.int32, or np.int64\n",
    "    :param sample: the sampled matrix\\array\n",
    "    :type sample: np.array\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    :return plhs: plhs sample array\n",
    "    :rtype plhs: np.array\n",
    "    :return plhs_slices: plhs sample slices (sub-samples)\n",
    "    :rtype plhs_slices: np.array\n",
    "    :return f_priori: objective function value before optimization\n",
    "    :rtype f_priori: float\n",
    "    :return f_posteriori: objective function value after optimization\n",
    "    :rtype f_posteriori: float\n",
    "\n",
    "\n",
    "    References:\n",
    "    -----------\n",
    "    .. [1] Ba, S., Myers, W.R., Brenneman, W.A., 2015. Optimal sliced Latin\n",
    "           hypercube designs. Technometrics 57 (4), 479e487.\n",
    "           http://dx.doi.org/10.1080/00401706.2014.957867\n",
    "    .. [2] Sheikholeslami, R., & Razavi, S. (2017). Progressive Latin Hypercube \n",
    "           Sampling: An efficient approach for robust sampling-based analysis of \n",
    "           environmental models. Environmental modelling & software, 93, 109-126\n",
    "\n",
    "\n",
    "    Contributors:\n",
    "    -------------\n",
    "    Sheikholeslami, Razi, (2017): algorithm, code in MATLAB (c)\n",
    "    Razavi, Saman, (2017): algorithm, code in MATLAB (c), supervision\n",
    "    Keshavarz, Kasra, (2021): code in Python 3\n",
    "    Matott, Shawn, (2019): code in C/++\n",
    "\n",
    "    '''\n",
    "\n",
    "    # check the dtype of input arguments\n",
    "    msg = (\"dtype of '{}' array must be 'int', 'numpy.int32' or 'numpy.int64'.\")\n",
    "    if type(sp) not in [int, np.int32, np.int64]:\n",
    "        raise ValueError(msg.format('sp'))\n",
    "    if type(slices) not in [int, np.int32, np.int64]:\n",
    "        raise ValueError(msg.format('slices'))\n",
    "\n",
    "    # check the number of slices and sample points\n",
    "    if (sp % slices) != 0:\n",
    "        raise ValueError(\"sample points must be a multiplier of slices.\")\n",
    "\n",
    "    # check the sign of the input arguments\n",
    "    sign_msg = (\"the sign of '{}' must be positive (>0).\")\n",
    "    if sp < 0:\n",
    "        raise ValueError(sign_msg.format('sp'))\n",
    "    if slices < 0:\n",
    "        raise ValueError(sign_msg.format('slices'))\n",
    "        \n",
    "    \n",
    "    slice_sp = sp // slices\n",
    "    # row-wise slicing - PLHS standard\n",
    "    sub_sample = np.array(np.split(sample, slices, axis=0))\n",
    "    # priori cost function value\n",
    "    f_priori = np.mean([_lhd_cost(sl_agg) for sl_agg in\n",
    "              [np.concatenate(sub_sample[0:t+1,...]) for t in range(slices)]])\n",
    "    \n",
    "    # let's find out the first two slices that results in the lowest\n",
    "    # cost function and make the original code more efficient...\n",
    "    # pay attention to axis=0, PLHS standard is row-wise...\n",
    "    indices = list(range(sub_sample.shape[0]))\n",
    "    least_cost = lambda idx: _lhd_cost(np.concatenate(np.take(sub_sample, idx, axis=0)))\n",
    "    greedy_indices = list(min(combinations(indices,2), key=least_cost)) # 2: pair\n",
    "    \n",
    "    # find the next slices in a loop and add its indice to the \n",
    "    # `greedy_indices` list\n",
    "    indices = list(set(indices) - set(greedy_indices))\n",
    "    for _ in range(len(indices)):\n",
    "        greedy_indices = list(min([greedy_indices+[idx] for idx in indices], key=least_cost))\n",
    "        indices = list(set(indices) - set(greedy_indices)) # same as above...\n",
    "    \n",
    "    # check the `posteriori` cost function value\n",
    "    # pay attention to axis=0, PLHS standard is row-wise...\n",
    "    plhs_slices = np.take(sub_sample, greedy_indices, axis=0)\n",
    "    plhs = np.concatenate(plhs_slices)\n",
    "    f_posteriori = np.mean([_lhd_cost(sl_agg) for sl_agg in \\\n",
    "                            [np.concatenate(plhs_slices[0:t+1,...]) for t in range(slices)]])\n",
    "    \n",
    "    return (plhs, plhs_slices, f_priori, f_posteriori)\n",
    "    \n",
    "\n",
    "def _lhd_cost(arr:np.ndarray, axis:int=1) -> float:\n",
    "    '''\n",
    "    Description:\n",
    "    ------------\n",
    "    This is a simple cost function used in PLHS Greedy algorithm\n",
    "    \n",
    "    \n",
    "    Arguments:\n",
    "    ----------\n",
    "    :param arr: the input array (nxd dimensions)\n",
    "    :type arr: np.array\n",
    "    :param axis: the axis along which the cost is calculated\n",
    "    :type axis: int, defaults to 1 in PLHS\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    :return f: the cost function\n",
    "    :rtype f: int, np.int32, np.int64\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # get the bins equal to the number of rows\n",
    "    # in PLHS, each row is a sample series, and each column\n",
    "    # corresponds to a parameter/factor/variable\n",
    "    edges = np.linspace(start=0, stop=1, num=arr.shape[0]+1)\n",
    "    f = -np.sum(_bin_count(np.digitize(arr, edges), axis=axis))\n",
    "    \n",
    "    return f\n",
    "\n",
    "\n",
    "def _bin_count(arr:np.ndarray, axis:int=0) -> np.ndarray:\n",
    "    '''\n",
    "    Description:\n",
    "    ------------\n",
    "    Calculates the number of unique values along the `axis` of the given\n",
    "    `arr`. This function is used in PLHS algorithm to check LHS-conformity \n",
    "    of the generated random samples.\n",
    "    \n",
    "    \n",
    "    Arguments:\n",
    "    ----------\n",
    "    :param arr: the input array of interest\n",
    "    :type arr: np.array\n",
    "    :param axis: the axis along which the unique values are counted\n",
    "    :type arr: int, `0` for `rows` and `1` for `columns`, defaults to 0\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    :return unique_count: the number of unique values along each axis\n",
    "    :rtype unique_count: np.array\n",
    "    \n",
    "    \n",
    "    Source/Credit:\n",
    "    --------------\n",
    "    .. [1] https://stackoverflow.com/questions/\n",
    "           48473056/number-of-unique-elements-per-row-in-a-numpy-array\n",
    "           (the most efficient method)\n",
    "    '''\n",
    "    if axis: # the method does operations row-wise...\n",
    "        arr = arr.T\n",
    "        \n",
    "    n = arr.max()+1\n",
    "    a_off = arr+(np.arange(arr.shape[0])[:,None])*n\n",
    "    M = arr.shape[0]*n\n",
    "    unique_count = (np.bincount(a_off.ravel(), minlength=M).reshape(-1,n)!=0).sum(1)\n",
    "    return unique_count\n",
    "\n",
    "\n",
    "def _sampler(sp:int, params:int, slices:int, seed:int=None) -> np.ndarray:\n",
    "    '''\n",
    "    Description:\n",
    "    ------------\n",
    "    A simple sampling algorithm to create lhs slices.\n",
    "\n",
    "\n",
    "    Arguments:\n",
    "    ----------\n",
    "    :param lb: lower bound of the sequence\n",
    "    :type lb: one of int, np.int32, np.int64\n",
    "    :param ub: upper bound of the sequence\n",
    "    :type ub: one of int, np.int32, np.int64\n",
    "    :param slices: the number of slices\n",
    "    :type slices: one of int, np.int32, np.int64\n",
    "    :param seed: seed number for randomization\n",
    "    :type seed: int, np.int32, np.int64\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    :return sample_array: the final sample array\n",
    "    :rtype sample_array: np.array\n",
    "\n",
    "\n",
    "    References:\n",
    "    -----------\n",
    "    .. [1] Ba, S., Myers, W.R., Brenneman, W.A., 2015. Optimal sliced Latin\n",
    "           hypercube designs. Technometrics 57 (4), 479e487.\n",
    "           http://dx.doi.org/10.1080/00401706.2014.957867.\n",
    "    .. [2] Sheikholeslami, R., & Razavi, S. (2017). Progressive Latin Hypercube\n",
    "           Sampling: An efficient approach for robust sampling-based analysis of\n",
    "           environmental models. Environmental modelling & software, 93, 109-126\n",
    "\n",
    "\n",
    "    Contributors:\n",
    "    -------------\n",
    "    Sheikholeslami, Razi, (2017): algorithm, code in MATLAB (c)\n",
    "    Razavi, Saman, (2017): supervision\n",
    "    Keshavarz, Kasra, (2021): code in Python 3\n",
    "    Matott, Shawn, (2019): code in C/++\n",
    "    '''\n",
    "    \n",
    "    # define the randomization seed number\n",
    "    if seed:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "\n",
    "    # check the dtype of input arguments\n",
    "    msg = (\"dtype of '{}' array must be 'int', 'numpy.int32' or 'numpy.int64'.\")\n",
    "    if type(sp) not in [int, np.int32, np.int64]:\n",
    "        raise ValueError(msg.format('sp'))\n",
    "    if type(params) not in [int, np.int32, np.int64]:\n",
    "        raise ValueError(msg.format('params'))\n",
    "    if type(slices) not in [int, np.int32, np.int64]:\n",
    "        raise ValueError(msg.format('slices'))\n",
    "\n",
    "    # check the number of slices and sample points\n",
    "    if (sp % slices) != 0:\n",
    "        raise ValueError(\"sample points must be a multiplier of slices.\")\n",
    "\n",
    "    # check the sign of the input arguments\n",
    "    sign_msg = (\"the sign of '{}' must be positive (>0).\")\n",
    "    if sp < 0:\n",
    "        raise ValueError(sign_msg.format('sp'))\n",
    "    if params < 0:\n",
    "        raise ValueError(sign_msg.format('params'))\n",
    "    if slices < 0:\n",
    "        raise ValueError(sign_msg.format('slices'))\n",
    "\n",
    "\n",
    "    # calculate the number of slices\n",
    "    slice_sp = sp // slices # to get int\n",
    "\n",
    "    # generate slices using sampling (int) without permutation\n",
    "    rand_perm = lambda slice_sp, slices: np.concatenate([np.random.permutation(slice_sp)+1 for _j in range(slices)])\n",
    "    sample_array = np.stack([rand_perm(slice_sp, slices) for _i in range(params)])\n",
    "    \n",
    "    # DEBUG\n",
    "    # print('sample_array:')\n",
    "    # print(sample_array)\n",
    "    # END DEBUG\n",
    "\n",
    "    # positional function definition\n",
    "    slice_spec = lambda row, slice_sp: np.stack([(row==_j+1) for _j in range(slice_sp)])\n",
    "\n",
    "    # row-wise assessment\n",
    "    for _row in range(0, sample_array.shape[0]):\n",
    "        position_array = slice_spec(sample_array[_row, :], slice_sp)\n",
    "        for kk in range(0, slice_sp):\n",
    "            lb = (kk*slices)+1\n",
    "            ub = (kk+1)*slices\n",
    "            perm = _perm_intv(lb, ub, slices, seed)\n",
    "            try:\n",
    "                sample_array[_row, position_array[kk, :]] = perm\n",
    "            except: # sometimes a number might be missing due to randomness...\n",
    "                raise RuntimeError(\"error! change the seed number and try again.\")\n",
    "    sample_array = np.random.uniform(sample_array-1, sample_array)\n",
    "    sample_array /= sp\n",
    "\n",
    "    return sample_array.T\n",
    "\n",
    "\n",
    "def _perm_intv(lb:int, ub:int, slices:int, seed:int=None) -> np.ndarray:\n",
    "    '''\n",
    "    Description:\n",
    "    ------------\n",
    "    A simple random sampling given the lower and upper bounds,\n",
    "    without permutation, and amongst the integers in the interval\n",
    "\n",
    "\n",
    "    Arguments:\n",
    "    ----------\n",
    "    :param lb: lower bound of the sequence\n",
    "    :type lb: one of int, np.int32, np.int64\n",
    "    :param ub: upper bound of the sequence\n",
    "    :type ub: one of int, np.int32, np.int64\n",
    "    :param slices: the number of slices\n",
    "    :type slices: one of int, np.int32, np.int64\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    :return perm: the sampled np.array\n",
    "    :type perm: np.array\n",
    "\n",
    "\n",
    "    Contributors:\n",
    "    -------------\n",
    "    Sheikholeslami, Razi, (2017): algorithm, code in MATLAB (c)\n",
    "    Razavi, Saman, (2017): supervision\n",
    "    Keshavarz, Kasra, (2021): code in Python 3\n",
    "    Matott, Shawn, (2019): code in C/++\n",
    "    '''\n",
    "\n",
    "    # define the randomization seed number\n",
    "    if seed:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    # a simple sampling without permutation algorithm\n",
    "    length = np.abs(ub-lb)+1\n",
    "    perm   = np.arange(start=lb, stop=ub+1, step=1)\n",
    "    for k in range(2, length+1):\n",
    "        index1 = np.int(np.ceil(np.random.rand() * k))\n",
    "        index2 = perm[k-1]\n",
    "        perm[k-1] = perm[index1-1]\n",
    "        perm[index1-1] = index2\n",
    "    perm = perm[0:slices+1]\n",
    "    \n",
    "    # DEBUG\n",
    "    # print('perm is:')\n",
    "    # print(perm)\n",
    "    # END DEBUG\n",
    "\n",
    "    return perm\n",
    "\n",
    "\n",
    "def _knn(arr1:np.ndarray, arr2:np.ndarray, k:int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \n",
    "    '''\n",
    "    Description:\n",
    "    ------------\n",
    "    A simple KNN ML algorithm to find the minimum Euclidean distance\n",
    "    \n",
    "    \n",
    "    Arguments:\n",
    "    ----------\n",
    "    :param arr1: the first array of data\n",
    "    :type arr1: np.array, `n` rows and `d` columns\n",
    "    :param arr2: the second array of data\n",
    "    :type arr2: np.array, `m` rows and `d` columns\n",
    "    :param k: the number of neighbors\n",
    "    :type k: int, np.int32, np.int64\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    :return distances: Euclidean distances between `arr1` and `arr2` points\n",
    "    :rtype distances: np.array\n",
    "    :return indices: the indices of the distances between `arr1` and `arr2` \n",
    "                     points\n",
    "    :rtype indices: np.array\n",
    "    '''\n",
    "    \n",
    "    # calculating the distance between points\n",
    "    distances = -2 * arr1@arr2.T + np.sum(arr2**2,axis=1) + \\\n",
    "                     np.sum(arr1**2,axis=1)[:, np.newaxis]\n",
    "    \n",
    "    # taking into account the floating point discrepancies \n",
    "    distances[distances < 0] = 0\n",
    "    distances = distances**.5\n",
    "    indices = np.argsort(distances, 0)\n",
    "    distances = np.sort(distances,0)\n",
    "    \n",
    "    # reshaping the arrays\n",
    "    indices = indices[0:k, : ].T\n",
    "    \n",
    "#     DEBUG\n",
    "#     print(distances)\n",
    "#     print(distances.shape)\n",
    "#     END DEBUG\n",
    "    \n",
    "    distances = distances[0:k, : ].T.flatten().reshape(arr1.shape[0], k)\n",
    "    \n",
    "    return indices, distances\n",
    "\n",
    "\n",
    "def _get_min_distance(arr:np.ndarray, k:int=3) -> float:\n",
    "    '''\n",
    "    Description:\n",
    "    ------------\n",
    "    Calculates the minimum Euclidean distance between sample points as a measure\n",
    "    of sparsity of the sampling space\n",
    "    \n",
    "    \n",
    "    Arguments:\n",
    "    ----------\n",
    "    :param arr: the input array of any size\n",
    "    :type arr: np.array\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    :return min_distance: the minimum distance calculated\n",
    "    :rtype min_distance: np.float\n",
    "    '''\n",
    "    \n",
    "    idx, distance = _knn(arr, arr, k) # idx index start from 0\n",
    "    min_distance = np.min(distance[:, 1])\n",
    "    \n",
    "    return min_distance\n",
    "\n",
    "\n",
    "def _get_corr(arr:np.ndarray) -> float:\n",
    "    '''\n",
    "    Description:\n",
    "    ------------\n",
    "    Calculates the correlation between the sample columns and\n",
    "    reports the sum of squared correlation values.\n",
    "    \n",
    "    \n",
    "    Arguments:\n",
    "    ----------\n",
    "    :param arr: the input array of any size\n",
    "    :type arr: np.array\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    :return sq_corr: sum of the squared correlation values\n",
    "    :rtype sq_corr: np.float\n",
    "    '''\n",
    "\n",
    "    return sum(sum(np.triu(np.corrcoef(arr, rowvar=False))**2))\n",
    "\n",
    "\n",
    "def _get_corr_sub(arr:np.ndarray) -> float:\n",
    "    '''\n",
    "    Description:\n",
    "    ------------\n",
    "    Calculates the correlation between the sample columns and\n",
    "    reports the sum of squared correlation values.\n",
    "    \n",
    "    \n",
    "    Arguments:\n",
    "    ----------\n",
    "    :param arr: the input array of any size\n",
    "    :type arr: np.array\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    :return sq_corr: sum of the squared correlation values\n",
    "    :rtype sq_corr: np.float\n",
    "    '''\n",
    "\n",
    "    return np.mean(np.array([_get_corr(x) for x in arr]))\n",
    "\n",
    "\n",
    "def _get_min_distance_sub(arr:np.ndarray, k:int=3) -> float:\n",
    "    '''\n",
    "    Description:\n",
    "    ------------\n",
    "    Calculates the minimum Euclidean distance between sample points as a measure\n",
    "    of sparsity of the sampling space in each slice. The returned value is aver-\n",
    "    aged amongst the minimum value of the slices.\n",
    "    \n",
    "    \n",
    "    Arguments:\n",
    "    ----------\n",
    "    :param arr: the input array of any size\n",
    "    :type arr: np.array, n x m dimension\n",
    "    :param k: the number of neightbors\n",
    "    :type k: int, np.int32, np.int64\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    :return min_distance: the minimum distance calculated\n",
    "    :rtype min_distance: np.float\n",
    "    '''\n",
    "    \n",
    "    return np.mean(np.array([_get_min_distance(x, k) for x in arr]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CWcuv7PqyPQ0"
   },
   "outputs": [],
   "source": [
    "def plhs(sp:int, params:int, slices:int, seed=None, iterations=10, criterion='maximin') -> Tuple[np.ndarray, np.ndarray]:\n",
    "    '''\n",
    "    Description:\n",
    "    ------------\n",
    "    This function created SLHS samples, based on [1] and [2]\n",
    "    \n",
    "    \n",
    "    Arguments:\n",
    "    ----------\n",
    "    :param lb: lower bound of the sequence\n",
    "    :type lb: one of int, np.int32, np.int64\n",
    "    :param ub: upper bound of the sequence\n",
    "    :type ub: one of int, np.int32, np.int64\n",
    "    :param slices: the number of slices\n",
    "    :type slices: one of int, np.int32, np.int64\n",
    "    :param seed: seed number for randomization\n",
    "    :type seed: int, np.int32, np.int64\n",
    "    :param iter: maximum iteration number \n",
    "    :type iter: int, np.int32, np.int64, optional\n",
    "    :param criterion: the criterion for assessing the quality of sample points\n",
    "                      the available options are: 'maximin' and 'correlation',\n",
    "                      defaults to 'maximin'\n",
    "    :type criterion: str, optional\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    :return plhs_sample_x: the final slhs sample array based on 'x' criterion\n",
    "    :rtype plhs_sample_x: np.array\n",
    "    \n",
    "    \n",
    "    References:\n",
    "    -----------\n",
    "    .. [1] Ba, S., Myers, W.R., Brenneman, W.A., 2015. Optimal sliced Latin\n",
    "           hypercube designs. Technometrics 57 (4), 479e487.\n",
    "           http://dx.doi.org/10.1080/00401706.2014.957867\n",
    "    .. [2] Sheikholeslami, R., & Razavi, S. (2017). Progressive Latin Hypercube \n",
    "           Sampling: An efficient approach for robust sampling-based analysis of \n",
    "           environmental models. Environmental modelling & software, 93, 109-126\n",
    "    \n",
    "    \n",
    "    Contributors:\n",
    "    -------------\n",
    "    Sheikholeslami, Razi, (2017): algorithm, code in MATLAB (c)\n",
    "    Razavi, Saman, (2017): algorithm code in MATLAB (c), supervision\n",
    "    Keshavarz, Kasra, (2021): code in Python 3\n",
    "    Matott, Shawn, (2019): code in C/++\n",
    "    '''\n",
    "    \n",
    "    slice_sp = sp // slices\n",
    "    \n",
    "    # iterate given the number of iterations and choose the best sample\n",
    "    slhs_list = []\n",
    "    plhs_list = []\n",
    "    \n",
    "    for _iter in range(iterations):\n",
    "        if seed:\n",
    "            seed += seed\n",
    "        slhs_list.append(slhs(sp, params, slices, seed, iterations, criterion)[0])\n",
    "        plhs_list.append(_greedy_plhs(sp, slices, slhs_list[_iter]))\n",
    "    \n",
    "    cost_f_posteriori = [trial[-1] for trial in plhs_list]\n",
    "    min_cost_idx = cost_f_posteriori.index(min(cost_f_posteriori))\n",
    "    plhs_sample = plhs_list[min_cost_idx][0] # first returned item\n",
    "    \n",
    "    # This does not make sense to me. User can decide what to do\n",
    "    # regarding the number of iterations and choosing the best\n",
    "    # sample!\n",
    "\n",
    "    return plhs_sample\n",
    "\n",
    "\n",
    "def slhs(sp, params, slices, seed=None, iterations=20, criterion='maximin') -> Tuple[np.ndarray, np.ndarray]:\n",
    "    '''\n",
    "    Description:\n",
    "    ------------\n",
    "    This function created SLHS samples, based on [1] and [2]. In\n",
    "    order to find optimal ordering of slices the KNN method is \n",
    "    utilized.\n",
    "    \n",
    "    \n",
    "    Arguments:\n",
    "    ----------\n",
    "    :param sp: number of sample points\n",
    "    :type sp: one of int, np.int32, np.int64\n",
    "    :param params: number of parameters/variables/factors\n",
    "    :type params: one of int, np.int32, np.int64\n",
    "    :param slices: number of slices\n",
    "    :type slices: one of int, np.int32, np.int64\n",
    "    :param seed: seed number for randomization\n",
    "    :type seed: int, np.int32, np.int64, optional\n",
    "    :param _iter: maximum iteration number \n",
    "    :type _iter: int, np.int32, np.int64, optional\n",
    "    :param criterion: the criterion for assessing the quality of sample points;\n",
    "                      the available options are: 'maximin' and 'correlation',\n",
    "                      defaults to 'maximin'\n",
    "    :type criterion: str\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    :return slhs_sample_x: the final slhs sample array based on 'x' criterion\n",
    "    :rtype slhs_sample_x: np.array\n",
    "    :return slhs_sample_x_slice: the final slhs sample array slices based on\n",
    "                                 'x' criterion\n",
    "    :rtype slhs_sample_x_slice: np.array\n",
    "    \n",
    "    \n",
    "    References:\n",
    "    -----------\n",
    "    .. [1] Ba, S., Myers, W.R., Brenneman, W.A., 2015. Optimal sliced Latin\n",
    "           hypercube designs. Technometrics 57 (4), 479e487.\n",
    "           http://dx.doi.org/10.1080/00401706.2014.957867\n",
    "    .. [2] Sheikholeslami, R., & Razavi, S. (2017). Progressive Latin Hypercube \n",
    "           Sampling: An efficient approach for robust sampling-based analysis of \n",
    "           environmental models. Environmental modelling & software, 93, 109-126\n",
    "    \n",
    "    \n",
    "    Contributors:\n",
    "    -------------\n",
    "    Sheikholeslami, Razi, (2017): algorithm, code in MATLAB (c) vars-tool\n",
    "    Razavi, Saman, (2017): supervision, vars-tool\n",
    "    Keshavarz, Kasra, (2021): code in Python 3\n",
    "    Matott, Shawn, (2019): code in C/++\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # define the seed number\n",
    "    if seed:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "\n",
    "    # Check the inputs and raise appropriate exceptions\n",
    "    msg_crt = (\"'{}' is not defined; available options: 'maximin', 'correlation'\")\n",
    "    if type(criterion) is not str:\n",
    "        raise TypeError(msg_crt.format(str(criterion)))\n",
    "    if criterion not in ['maximin', 'correlation']:\n",
    "        raise ValueError(msg_crt.format(criterion))\n",
    "    \n",
    "    # calculate the number of slices\n",
    "    slice_sp = sp // slices # to get int\n",
    "    \n",
    "    # Check the criterion\n",
    "    if criterion == 'maximin':\n",
    "        best_sample = _sampler(sp, params, slices)\n",
    "        best_sub_sample = best_sample.reshape((slices, slice_sp, params))\n",
    "        best_sample_cost = _get_min_distance(best_sample, k=3)\n",
    "        best_sub_sample_cost = _get_min_distance_sub(best_sub_sample)\n",
    "        cost_func = np.mean([best_sample_cost, best_sub_sample_cost])\n",
    "        \n",
    "        for it in range(iterations):\n",
    "            new_sample = _sampler(sp, params, slices)\n",
    "            new_sub_sample = new_sample.reshape((slices, slice_sp, params))\n",
    "            new_sample_cost = _get_min_distance(new_sample)\n",
    "            new_sub_sample_cost = _get_min_distance_sub(new_sub_sample)\n",
    "            new_cost_func = np.mean([new_sample_cost, new_sub_sample_cost])\n",
    "            \n",
    "            # check the cost function value\n",
    "            if new_cost_func > cost_func:\n",
    "                best_sample = new_sample\n",
    "                cost_func = new_cost_func\n",
    "        \n",
    "        slhs_sample_maximin = best_sample\n",
    "        slhs_sample_maximin_slice = slhs_sample_maximin.reshape((slices, slice_sp, params))\n",
    "\n",
    "        return slhs_sample_maximin, slhs_sample_maximin_slice\n",
    "\n",
    "    elif criterion == 'correlation':\n",
    "        best_sample = _sampler(sp, params, slices)\n",
    "        best_sub_sample = best_sample.reshape((slices, slice_sp, params))\n",
    "        best_sample_cost = _get_corr(best_sample)\n",
    "        best_sub_sample_cost = _get_corr_sub(best_sub_sample)\n",
    "        cost_func = np.mean([best_sample_cost, best_sub_sample_cost])\n",
    "        \n",
    "        for it in range(iterations):\n",
    "            new_sample = _sampler(sp, params, slices)\n",
    "            new_sub_sample = new_sample.reshape((slices, slice_sp, params))\n",
    "            new_sample_cost = _get_corr(new_sample)\n",
    "            new_sub_sample_cost = _get_corr_sub(new_sub_sample)\n",
    "            new_cost_func = np.mean([new_sample_cost, new_sub_sample_cost])\n",
    "            \n",
    "            # check the cost function value\n",
    "            if new_cost_func < cost_func:\n",
    "                best_sample = new_sample\n",
    "                cost_func = new_cost_func\n",
    "        \n",
    "        slhs_sample_correl = best_sample\n",
    "        slhs_sample_correl_slice = slhs_sample_correl.reshape((slices, slice_sp, params))\n",
    "\n",
    "        return slhs_sample_correl, slhs_sample_correl_slice    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "plhs.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
