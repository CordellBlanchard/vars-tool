{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "965cc71f-c5e9-4c62-b596-29ed91199872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stat\n",
    "from scipy.optimize import newton_krylov\n",
    "from scipy.integrate import dblquad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "993d8e78-2fe0-481f-a6da-1d391d764910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearAdditive(x):\n",
    "    term1 = 2*x[0]\n",
    "    term2 = 3*x[1]\n",
    "    return term1 + term2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58b8067c-ab82-41f8-9156-f24850ef4ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rx2rn(distpair_type, param1, param2, rxpair):\n",
    "    \n",
    "    # getting the inverse cdf of distribution 1\n",
    "    if (distpair_type[0] == 'unif'):\n",
    "        mu1 = (param1[1] + param1[0])/2\n",
    "        std1 = (param1[1] - param1[0])/12**0.5\n",
    "        inv_cdf1 = lambda x : param1[0] + (param1[1] - param1[0])*x\n",
    "    elif (distpair_type[0] == 'norm'):\n",
    "        mu1 = param1[0]\n",
    "        std1 = param1[1]\n",
    "        inv_cdf1 = lambda x : stat.norm.ppf(x, mu1, std1)\n",
    "    elif (distpair_type[0] == 'triangle'):\n",
    "        mu1 = (param1[0] + param1[1] + param1[2])/3\n",
    "        std1 = (np.sqrt(param1[0]**2+param1[1]**2+param1[2]**2-param1[0]*param1[1]-param1[0]*param1[2]-param1[1]*param1[2]))/np.sqrt(18)\n",
    "        mid1=(param1[2]-param1[0])/(param1[1]-param1[0])\n",
    "        term11= (param1[1]-param1[0])*(param1[2]-param1[0])\n",
    "        term21= (param1[1]-param1[0])*(param1[1]-param1[2])\n",
    "        inv_cdf1 = lambda x : ((param1[0]+np.sqrt(term11)*np.sqrt(x/1))*((x>=0).astype(int))*((x<mid1).astype(int)) + (param1[1]-np.sqrt(term21)*np.sqrt(1-x))*((x>=mid1).astype(int))*((x<1).astype(int)))\n",
    "    elif (distpair_type[0] == 'lognorm'):\n",
    "        mu1= param1[0]\n",
    "        std1=param1[1]\n",
    "        # compute associated normal\n",
    "        cv=std1/mu1**2\n",
    "        m = np.log(mu1/(np.sqrt(1+cv)))\n",
    "        v = np.sqrt(np.log(1+cv))           \n",
    "        inv_cdf1 = lambda x : stat.lognorm.ppf(x, scale=np.exp(m), s=v, loc=0)\n",
    "    elif (distpair_type[0] == 'expo'):\n",
    "        lamda= param1[0]\n",
    "        mu1=1/lamda\n",
    "        std1=1/(lamda**2)\n",
    "        inv_cdf1 = lambda x : stat.expon.ppf(x, scale=mu1)\n",
    "    elif (distpair_type[0] == 'gev'):\n",
    "        mu=param1[0] #location\n",
    "        sigma=param1[1] #scale\n",
    "        k1=param1[2] #shape\n",
    "        inv_cdf1 = lambda x : stat.genextreme.ppf(x,c=k1,scale=sigma,loc=mu);\n",
    "        [mu1,std1] = stat.genextreme.stats(k1,scale=sigma,loc=mu);\n",
    "        \n",
    "    # getting the inverse cdf of distribution 2\n",
    "    if (distpair_type[1] == 'unif'):\n",
    "        mu2 = (param2[1] + param2[0])/2\n",
    "        std2 = (param2[1] - param2[0])/12**0.5\n",
    "        inv_cdf2 = lambda x : param2[0] + (param2[1] - param2[0])*x\n",
    "    elif (distpair_type[1] == 'norm'):\n",
    "        mu2 = param2[0]\n",
    "        std2 = param2[1]\n",
    "        inv_cdf2 = lambda x : stat.norm.ppf(x, mu2, std2)\n",
    "    elif (distpair_type[1] == 'triangle'):\n",
    "        mu2 = (param2[0] + param2[1] + param2[2])/3\n",
    "        std2 = (np.sqrt(param2[0]**2+param2[1]**2+param2[2]**2-param2[0]*param2[1]-param2[0]*param2[2]-param2[1]*param2[2]))/np.sqrt(18)\n",
    "        mid2=(param2[2]-param2[0])/(param2[1]-param2[0])\n",
    "        term12= (param2[1]-param2[0])*(param2[2]-param2[0])\n",
    "        term22= (param2[1]-param2[0])*(param2[1]-param2[2])\n",
    "        inv_cdf2 = lambda x : ((param2[0]+np.sqrt(term12)*np.sqrt(x/1))*((x>=0).astype(int))*((x<mid2).astype(int)) + (param2[1]-np.sqrt(term22)*np.sqrt(1-x))*((x>=mid1).astype(int))*((x<1).astype(int)))\n",
    "    elif (distpair_type[1] == 'lognorm'):\n",
    "        mu2= param2[0]\n",
    "        std2=param2[1]\n",
    "        # compute associated normal\n",
    "        cv=std2/mu2**2\n",
    "        m = np.log(mu2/(np.sqrt(1+cv)))\n",
    "        v = np.sqrt(np.log(1+cv))           \n",
    "        inv_cdf2 = lambda x : stat.lognorm.ppf(x, scale=np.exp(m), s=v, loc=0)\n",
    "    elif (distpair_type[1] == 'expo'):\n",
    "        lamda= param2[0]\n",
    "        mu2=1/lamda\n",
    "        std2=1/(lamda**2)\n",
    "        inv_cdf2 = lambda x : stat.expon.ppf(x, scale=mu2)\n",
    "    elif (distpair_type[1] == 'gev'):\n",
    "        mu=param2[0] #location\n",
    "        sigma=param2[1] #scale\n",
    "        k2=param2[2] #shape\n",
    "        inv_cdf2 = lambda x : stat.genextreme.ppf(x,c=k2,scale=sigma,loc=mu);\n",
    "        [mu2,std2] = stat.genextreme.stats(k2,scale=sigma,loc=mu);\n",
    "    \n",
    "    # bivariate standard normal distribution\n",
    "    stdnorm2_pdf = lambda x1, x2 : np.exp(-1*(x1**2 + x2**2)/2.0)/(2.0*np.pi)\n",
    "    \n",
    "    # integral bound zmax=5.0, zmin = -5.0\n",
    "    integrand = lambda x1, x2 : inv_cdf1(stat.norm.cdf(x1*np.sqrt(1-rxpair**2)+ rxpair*x2,0,1))*inv_cdf2(stat.norm.cdf(x2,0,1))*stdnorm2_pdf(x1, x2)\n",
    "    # compute double integral of integrand with x1 ranging from -5.0 to 5.0 and x2 ranging from -5.0 to 5.0\n",
    "    rn = (dblquad(integrand, -5.0, 5.0, lambda x : -5.0, lambda x : 5.0) - mu1*mu2)/(std1*std2)\n",
    "    \n",
    "    return rn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e915ce16-5f60-4286-9cfe-74e0d8f9e4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rn2rx(distpair_type, param1, param2, rnpair):    \n",
    "    fun = lambda r : (rnpair - rx2rn(distpair_type, param1, param2, r))\n",
    "    # try to find point x where fun(x) = 0\n",
    "    try:\n",
    "        rx = newton_krylov(fun, rnpair, x_tol=1e-5)\n",
    "    except:\n",
    "        rx = rnpair\n",
    "            \n",
    "    return rx    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7130e67-255f-457e-b9c6-7c2d055e0930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_2_cornorm(parameters, corr_mat):\n",
    "    # store parameter info in a list\n",
    "    param_info = list(parameters.values())\n",
    "    \n",
    "    corr_n = np.eye(corr_mat.shape[0], corr_mat.shape[1])\n",
    "    for i in range(0, corr_mat.shape[0] - 1):\n",
    "        for j in range(i+1, corr_mat.shape[0]):\n",
    "            # input paramter info (lb, ub, ?, dist type)\n",
    "            corr_n[i][j] = rn2rx([param_info[i][3], param_info[j][3]], [param_info[i][0], param_info[i][1], param_info[i][2]],[param_info[j][0], param_info[j][1], param_info[j][2]],corr_mat[i][j])\n",
    "            # matrix is symmetrical\n",
    "            corr_n[j][i] = corr_n[i][j]\n",
    "    return corr_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bad9f51-b1e7-4d41-85b9-482766efa263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n2x_transform(norm_vectors, parameters):\n",
    "    # Transform from correlated standard normal to original distributions\n",
    "    param_info = list(parameters.values())\n",
    "    \n",
    "    # \n",
    "    k = norm_vectors.shape[1]   \n",
    "    x = np.zeros(norm_vectors.shape)\n",
    "\n",
    "    for i in range(0, k):\n",
    "        if param_info[i][3] == 'unif':\n",
    "            lb = param_info[i][0]\n",
    "            ub = param_info[i][1]\n",
    "\n",
    "            x[:, i] = lb + (ub - lb)*stat.norm.cdf(norm_vectors[:, i],0,1)\n",
    "        elif param_info[i][3] == 'norm':\n",
    "            mu = param_info[i][0]\n",
    "            std = param_info[i][1]\n",
    "\n",
    "            x[:, i] = stat.norm.ppf(stat.norm.cdf(norm_vectors[:, i],0,1), mu, std)\n",
    "        elif param_info[i][3] == 'triangle':\n",
    "            a = param_info[i][0]\n",
    "            b = param_info[i][1]\n",
    "            c = param_info[i][2]\n",
    "            mid = (c-a)/(b-a)\n",
    "            term1 = (b-a)*(c-a)\n",
    "            term2 = (b-a)*(b-c)\n",
    "            x_norm = stat.norm.cdf(norm_vector[:, i],0,1)\n",
    "            x[:, i] = (a+np.sqrt(term1)*np.sqrt(x_norm))*((x_norm >= 0).astype(int))*((x_norm < mid).astype(int))+(b-np.sqrt(term2)*np.sqrt((1-x_norm)))*((x_norm >= mid).astype(int))*((x_norm < 1).astype(int))\n",
    "        elif param_info[i][3] == 'lognorm':\n",
    "            mu = param_info[i][0]\n",
    "            std = param_info[i][1]\n",
    "            term1 = std/mu**2\n",
    "            m = np.log(mu/(np.sqrt(1+term1)))\n",
    "            v = np.sqrt(np.log(1+term1))\n",
    "            x[:, i] = np.lognorm.ppf(stat.norm.cdf(norm_vectors[:, i],0,1), scale=np.exp(mu), s=std, loc=0)\n",
    "        elif param_info[i][3] == 'expo':\n",
    "            mu = param_info[i][0]\n",
    "            x[:, i] = np.expon.ppf(stat.norm.cdf(norm_vectors[:, i],0,1), scale=mu)\n",
    "        elif param_info[i][3] == 'gev':\n",
    "            mu = param_info[i][0] # location\n",
    "            sigma = param_info[i][1] # scale\n",
    "            k = param_info[i][2] # shape\n",
    "            x[:, i] = stat.genextreme.ppf(stat.norm.cdf(norm_vectors[:, i],0,1),c=k,scale=sigma,loc=mu)\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4c69bdf9-a8fa-4ed3-8291-a217af723c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GVARS inputs\n",
    "seed = 12345678\n",
    "num_stars = 20\n",
    "num_dir_samples = 50\n",
    "delta_h = 0.1\n",
    "ivars_scales = [0.1, 0.3, 0.5]\n",
    "parameters = {'x1' : (0, 1, None, 'norm'),\n",
    "              'x2' : (0, 1, None, 'norm')}\n",
    "corr_mat = np.array([[1, 0.6], [0.6, 1]])\n",
    "n_var = len(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "32b8ddd4-5795-4d80-a3d6-59c8d4c7bd27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 0.6],\n",
       "       [0.6, 1. ]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_mat = map_2_cornorm(parameters, corr_mat)\n",
    "cov_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3ece33a3-9933-4526-a4d5-a04cef976a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.13451836, -0.13783305],\n",
       "       [ 0.33674871, -0.31507833],\n",
       "       [-0.66975342,  0.9921188 ],\n",
       "       [-0.35329794,  1.78738719],\n",
       "       [-0.49948636, -0.65152755],\n",
       "       [ 3.33039663, -0.81730169],\n",
       "       [-0.87460658,  0.02121665],\n",
       "       [ 0.16445247,  1.6950202 ],\n",
       "       [-0.59350673,  0.9959278 ],\n",
       "       [-0.73604291, -0.53098172],\n",
       "       [-0.32087045, -0.78818939],\n",
       "       [ 0.49734254, -1.49361469],\n",
       "       [-0.62327968, -0.9708674 ],\n",
       "       [ 1.01796246, -0.46186933],\n",
       "       [ 0.5373905 ,  0.97006237],\n",
       "       [ 0.45507399,  0.29825589],\n",
       "       [ 1.43268756, -0.66680277],\n",
       "       [ 1.00650393, -0.37071372],\n",
       "       [-0.3327895 ,  0.04643295],\n",
       "       [-1.51777611,  0.19747209]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate independent standard normal samples\n",
    "# the amount of samples is the same as the amount of stars\n",
    "U = np.random.multivariate_normal(np.zeros(n_var), np.eye(n_var), num_stars)\n",
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ba47dd74-d3c7-49b8-9b98-6a242c4d6623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.13451836, -0.02955543],\n",
       "       [ 0.33674871, -0.05001344],\n",
       "       [-0.66975342,  0.39184299],\n",
       "       [-0.35329794,  1.21793099],\n",
       "       [-0.49948636, -0.82091386],\n",
       "       [ 3.33039663,  1.34439663],\n",
       "       [-0.87460658, -0.50779062],\n",
       "       [ 0.16445247,  1.45468764],\n",
       "       [-0.59350673,  0.4406382 ],\n",
       "       [-0.73604291, -0.86641113],\n",
       "       [-0.32087045, -0.82307378],\n",
       "       [ 0.49734254, -0.89648623],\n",
       "       [-0.62327968, -1.15066173],\n",
       "       [ 1.01796246,  0.24128201],\n",
       "       [ 0.5373905 ,  1.0984842 ],\n",
       "       [ 0.45507399,  0.51164911],\n",
       "       [ 1.43268756,  0.32617032],\n",
       "       [ 1.00650393,  0.30733138],\n",
       "       [-0.3327895 , -0.16252734],\n",
       "       [-1.51777611, -0.752688  ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate correlated standard normal samples\n",
    "# the amount of samples is the same as the amount of stars\n",
    "cholU = np.linalg.cholesky(cov_mat)\n",
    "cholU = cholU.transpose() # to get in correct format for matrix multiplication\n",
    "Z = np.matmul(U,cholU) # transform samples to standard normal distribution\n",
    "display(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f868e7f9-4b2a-4839-8475-e5d20983e5da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.13451836, -0.02955543],\n",
       "       [ 0.33674871, -0.05001344],\n",
       "       [-0.66975342,  0.39184299],\n",
       "       [-0.35329794,  1.21793099],\n",
       "       [-0.49948636, -0.82091386],\n",
       "       [ 3.33039663,  1.34439663],\n",
       "       [-0.87460658, -0.50779062],\n",
       "       [ 0.16445247,  1.45468764],\n",
       "       [-0.59350673,  0.4406382 ],\n",
       "       [-0.73604291, -0.86641113],\n",
       "       [-0.32087045, -0.82307378],\n",
       "       [ 0.49734254, -0.89648623],\n",
       "       [-0.62327968, -1.15066173],\n",
       "       [ 1.01796246,  0.24128201],\n",
       "       [ 0.5373905 ,  1.0984842 ],\n",
       "       [ 0.45507399,  0.51164911],\n",
       "       [ 1.43268756,  0.32617032],\n",
       "       [ 1.00650393,  0.30733138],\n",
       "       [-0.3327895 , -0.16252734],\n",
       "       [-1.51777611, -0.752688  ]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate Nstar actual multivariate samples X\n",
    "X = n2x_transform(Z, parameters)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a2230473-12d9-44d0-ac79-ae93375fd8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define index matrix of complement subset\n",
    "compsub = np.empty([n_var, n_var-1])\n",
    "for i in range (0, n_var):\n",
    "\n",
    "    temp = np.arange(n_var)\n",
    "    compsub[i] = np.delete(temp, i)   \n",
    "compsub = compsub.astype(int)\n",
    "compsub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d461e084-e2de-4c2f-bff8-1544104e6d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computer coditional variance and conditional expectation for each star center\n",
    "chol_cond_std = []\n",
    "std_cond_norm = []\n",
    "mui_on_noti = np.zeros((len(Z), n_var))\n",
    "for i in range(0, n_var):\n",
    "    noti = compsub[i]\n",
    "    # 2 dimensional or greater matrix case\n",
    "    if (cov_mat[noti, noti].ndim >= 2):\n",
    "        cond_std = cov_mat[i][i] - cov_mat[i,noti]*np.linalg.inv(cov_mat[noti, noti])*cov_mat[noti,i]\n",
    "        chol_cond_std.append(np.linalg.cholesky(cond_std))\n",
    "        std_cond_norm.append(con_std)\n",
    "        for j in range(0, len(Z)):\n",
    "            mui_on_noti[j][i] = cov_mat[i,noti]*np.linalg.inv(cov_mat[noti, noti])*Z[j,noti]\n",
    "    # less then 2 dimenional matrix case\n",
    "    else:\n",
    "        cond_std = cov_mat[i][i] - cov_mat[i,noti]*cov_mat[noti, noti]*cov_mat[noti,i]\n",
    "        chol_cond_std.append(np.linalg.cholesky([[cond_std]]).flatten())\n",
    "        std_cond_norm.append(cond_std)\n",
    "        for j in range(0, len(Z)):\n",
    "            mui_on_noti[j][i] = cov_mat[i, noti]*cov_mat[noti, noti]*Z[j, noti]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3dc2d686-e7aa-4cd2-8613-c3eb42f0ac98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 2, 20)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate directional sample:\n",
    "# Create samples in correlated standard normal space\n",
    "all_section_condZ = []\n",
    "condZ = []\n",
    "for j in range(0, num_dir_samples):\n",
    "    stnrm_base = np.random.multivariate_normal(np.zeros(n_var), np.eye(n_var), num_stars)\n",
    "    for i in range(0, n_var):\n",
    "        condZ.append(stnrm_base[:, i]*chol_cond_std[i] + mui_on_noti[:, i])\n",
    "    all_section_condZ.append(condZ.copy())\n",
    "    condZ.clear()\n",
    "    \n",
    "np.array(all_section_condZ).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "82def3cd-1173-4d7b-9b5f-8880f9bf6acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 2, 20)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform to original distribution and compute response surface\n",
    "Xi_on_Xnoti = []\n",
    "tmp1 = []\n",
    "Xi_on_Xnoti_and_Xnoti_temp = []\n",
    "Xi_on_Xnoti_and_Xnoti = []\n",
    "for j in range(0, num_dir_samples):\n",
    "    for i in range(0, len(parameters)):\n",
    "        tmp1.append(n2x_transform(np.array([all_section_condZ[j][i]]).transpose(), parameters).flatten())\n",
    "        tmp2 = X.copy()\n",
    "        tmp2[:, i] = tmp1[i]\n",
    "        Xi_on_Xnoti_and_Xnoti_temp.append(tmp2.copy()) \n",
    "    # attatch results from tmp1 onto Xi_on_Xnoti and Xi_on_Xnoti_and_Xnoti\n",
    "    Xi_on_Xnoti.append(tmp1.copy())\n",
    "    tmp1.clear() # clear for next iteration\n",
    "    Xi_on_Xnoti_and_Xnoti.append(Xi_on_Xnoti_and_Xnoti_temp.copy())\n",
    "    Xi_on_Xnoti_and_Xnoti_temp.clear() # clear for next iteration\n",
    "        \n",
    "np.array(Xi_on_Xnoti).shape # check that shape is the same as all_section condZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca0e96a-49d4-40b6-8a83-d8059babd566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Star points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0ac6b2-fdc6-4ca2-905d-a398471f4837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4436064d-4fe2-4b39-9fe1-914ef0c66429",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
