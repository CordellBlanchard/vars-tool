{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity Analysis with Correlated Factors\n",
    "\n",
    "Notebook developed by Saman Razavi, Cordell Blanchard, and Kasra Keshavarz\n",
    "\n",
    "### For the Generalized VARS (G-VARS) method, please cite:\n",
    "\n",
    "Do, N. C., & Razavi, S. (2020). Correlation effects? A major but often neglected component in sensitivity and uncertainty analysis. Water Resources Research, 56(3), e2019WR025436. https://doi.org/10.1029/2019WR025436\n",
    "\n",
    "### For HBV-SASK, please cite:\n",
    "\n",
    "Razavi, S., Sheikholeslami, R., Gupta, H. V., & Haghnegahdar, A. (2019). VARS-TOOL: A toolbox for comprehensive, efficient, and robust sensitivity and uncertainty analysis. Environmental modelling & software, 112, 95-107. https://www.sciencedirect.com/science/article/pii/S1364815218304766"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 8: Sensitivity Analysis of HBV-SASK with correlated parameters\n",
    "### Objective:\n",
    "\n",
    "This notebook runs a sensitivity analysis of the HBV-SASK model when the model parameters may be correlated and/or non-uniformly distributed, through the *Generalized VARS (G-VARS)* method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First import the needed librares, including `GVARS` for G-VARS and the `Model` class for creating a wrapper around the desired model so that it can be inputted into VARS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import stats\n",
    "\n",
    "from varstool import GVARS, Model\n",
    "import hbv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduce the model\n",
    "\n",
    "Define the function of interest in sensitivity analysis. Here, the following function runs the HBV-SASK model and returns a single output such as a flux (e.g., *streamflow*) or state variable (e.g., *soil moisture*) at a certain point in time, or a signature response such as *the highest simulated peak* or an estimate of *the 100-year flood*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_HBV_SASK_3(x):\n",
    "    # preparing the inputs \n",
    "    \n",
    "    # in case you need to fix one or more parameters, remove them from your VARS experiment \n",
    "    # and supply the fixed parameter values below.    \n",
    "#     xtemp=pd.Series({'PM'   : 1  })\n",
    "#     x=x.append(xtemp)\n",
    "    \n",
    "    x.index = ['TT', 'C0', 'ETF', 'LP', 'FC', 'beta', 'FRAC', 'K1', 'alpha', 'K2', 'UBAS', 'PM']\n",
    "    param = x.to_dict()\n",
    "    \n",
    "    # running the HBV-SASK Model\n",
    "    basin = 'Oldman Basin'  # choose the basin of interest, either 'Oldman Basin' or 'Banff Basin'\n",
    "    flux, state, forcing = hbv.HBV_SASK(basin, param)\n",
    "\n",
    "    # choose the model output, three options below: \n",
    "    \n",
    "    # (1) for direct model response at a given time step, use the following\n",
    "#     start_day = end_day = '2005-10-05' # choose the date of interest\n",
    "#     out = flux['Q_cms'][start_day:end_day]\n",
    "    \n",
    "    # (2) for the highest peak based on simulated streamflow time series, use the following\n",
    "#     out = flux['Q_cms'].max()\n",
    "        \n",
    "    # (3) for an estimate of annual flood peak with a certain return period, use the following\n",
    "    return_period = 100      # in years\n",
    "    pr_of_exceedance = 1 - 1/return_period  \n",
    "    start_day = '1980-01-01' # choose the start date for the period of interest\n",
    "    end_day   = '2008-12-31' # choose the end date for the period of interest\n",
    "    \n",
    "    daily_time_series = flux['Q_cms'][start_day:end_day]\n",
    "    \n",
    "    annual_max_data = daily_time_series.resample('A').max() # extract annual maximums for the time period\n",
    "    \n",
    "#     dist_param = stats.distributions.gumbel_r.fit(annual_max_data)                         # use this line for gumbel distribution\n",
    "#     out = stats.distributions.gumbel_r.ppf(pr_of_exceedance, dist_param[0], dist_param[1]) # use this line for gumbel distribution\n",
    "\n",
    "    dist_param = stats.distributions.genextreme.fit(annual_max_data)                         # use this line for generalized extreme value distribution \n",
    "    out = stats.distributions.genextreme.ppf(pr_of_exceedance, dist_param[0], dist_param[1], dist_param[2]) # use this line for generalized extreme value distribution \n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrap the function of interest with the `Model` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HBV_model = Model(custom_HBV_SASK_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the wrapped function for an arbitrary input and check the model output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "343.166257015429"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=pd.Series({#name  #value\n",
    "             'TT'   : 0.0 ,\n",
    "             'C0'   : 1.0 ,\n",
    "             'ETF'  : 0.1 ,\n",
    "             'LP'   : 0.3 ,\n",
    "             'FC'   : 250 ,\n",
    "             'beta' : 2.0 ,\n",
    "             'FRAC' : 0.7 ,\n",
    "             'K1'   : 0.05,\n",
    "             'alpha': 1.5 ,\n",
    "             'K2'   : 0.01,\n",
    "             'UBAS' : 1.0 ,\n",
    "             'PM'   : 1.0 ,\n",
    "             })\n",
    "HBV_model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up a GVARS experiment\n",
    "\n",
    "Create a GVARS experiment and set its attributes. `GVARS` shares the attributes listed in Table 1 with `VARS`, while it also has some unique attributes explained after.\n",
    "***\n",
    "\n",
    "<p><center>Table 1. The attributes that GVARS inherits from VARS </center></p>\n",
    "\n",
    "| Attribute      | Description |\n",
    "| :-------------:|:----------- |\n",
    "|`num_stars`     | The total number of stars centers for VARS analysis                        |\n",
    "|`ivars_scales`  | The scales of interest for IVARS estimation, e.g, 0.1 and 0.5 correspond (0-0.1) and (0-0.5) <br /> note: can not have a scale larger than 0.5|\n",
    "|`star_centres`  | User-generated star centers - only used when a sampler is not chosen       |\n",
    "|`sampler`       | The sampling strategy: `rnd`, `lhs`, `plhs`, `sobol_seq`, or `halton_seq` for generation of star centers|\n",
    "|`seed`          | The seed number for randomization of the sampling strategy specified by `sampler`, <br /> only needed if a sampler was chosen  |\n",
    "|`model`         | The wrapper of your model in the `Model` class|\n",
    "|`bootstrap_flag`| This is a `True`/`False` value to turn on/off bootstrapping of VARS results   |\n",
    "|`bootstrap_size`| The number of sampling iterations with replacement via bootstrapping |\n",
    "|`bootstrap_ci`  | The level of confidence used in bootstrap reporting         |\n",
    "|`grouping_flag` | This is a `True`/`False` value to turn on/off grouping of VARS results   |\n",
    "|`num_grps`      | The number of groups you want to split your model paramaters into, <br /> if left blank the optimal number of groups will be calculated by VARS|\n",
    "|`report_verbose`| this is a `True`/`False` value that if `True` will display a loading bar <br /> to show the progession of the VARS analysis, else there will be no progression loading bar|\n",
    "\n",
    "***\n",
    "GVARS has three unique attributes: `parameters`, `corr_mat`, and `num_dir_samples`, as explained in the following.\n",
    "\n",
    "`parameters` includes the name of every model parameter, the distribution it follows, and the parameters specifying that distribution. The distributions currently available and their parameters are listed in Table 2.\n",
    "\n",
    "<p><center>Table 2. The parameter distributions currently supported in GVARS </center></p>\n",
    "\n",
    "| Distribution type        | Distribution parameter 1 | Distribution parameter 2 | Distribution parameter 3 | Distribution identifier |\n",
    "| :-----------------------:|:-----------------------: |:-----------------------: |:-----------------------: |:----------: |\n",
    "|uniform                   | lower bound              | upper bound              | None                     |  `unif`     |\n",
    "|triangle                  | lower bound              | upper bound              | mode                     |  `triangle` |\n",
    "|normal                    | mean                     | standard deviation       | None                     |  `norm`     |\n",
    "|lognormal                 | mean                     | standard deviation       | None                     |  `lognorm`  |\n",
    "|exponential               | mean                     | standard deviation       | None                     |  `expo`     |\n",
    "|generalized extreme value | location                 | scale                    | shape                    |  `gev`      |\n",
    "\n",
    "\n",
    "`corr_mat` is the correlation matrix which includes the Pearson correlation between every pair of parameters and must be defined as a numpy array.\n",
    "\n",
    "\n",
    "`num_dir_samples` is the number of samples GVARS takes along each direction for every star center. \n",
    "***\n",
    "**A \"good-to-know\" peice for advanced users:**\n",
    "\n",
    "In GVARS, the star-based sampling is modified to work with `num_stars` and `num_dir_samples`. This is unlike VARS where the star-based sampling works with `num_stars` and `delta_h`.\n",
    "\n",
    "GVARS still needs `delta_h` as an attribute for estimating and reporting directional variograms (not for sampling). As a rule-of-thumb, the user may set `delta_h` to be the reciprocal of `num_dir_samples`. For example, if num_dir_samples = 10, we suggest delta_h = 0.1.\n",
    "\n",
    "An advanced user may try other values of `delta_h` to extract more accurate results. In general, the smaller the `delta_h`, the more granular the results. But, the tradeoff with smaller values would be to have fewer pairs in the bins when estimating variograms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_parameters = { # name  dist_par1  dist_par1  dist_par1  dist_type\n",
    "                 'TT'   : (  0.940  ,  0.980  ,   None   , 'unif'     ),\n",
    "                 'C0'   : (  0.782  ,  0.003  ,   None   , 'norm'     ),\n",
    "                 'ETF'  : (  0.126  ,  0.008  ,   None   , 'norm'     ),\n",
    "                 'LP'   : (  0.670  ,  0.018  ,   None   , 'norm'     ),\n",
    "                 'FC'   : (  227.53 ,  6.930  ,   None   , 'norm'     ),\n",
    "                 'beta' : (  2.600  ,  3.000  ,  3.000   , 'triangle' ),\n",
    "                 'FRAC' : (  0.628  ,  0.011  ,   None   , 'norm'     ),\n",
    "                 'K1'   : (  0.050  ,  0.054  ,  0.050   , 'triangle' ),\n",
    "                 'alpha': (  1.602  ,  0.011  ,   None   , 'norm'     ),\n",
    "                 'K2'   : (  0.022  ,  0.001  ,   None   , 'norm'     ),\n",
    "                 'UBAS' : (  1.000  ,  1.200  ,  1.000   , 'triangle'  ),\n",
    "                 'PM'   : (  0.980  ,  1.020  ,   None   , 'unif'     ),}\n",
    "\n",
    "my_corr_mat = np.array([[    1, 0.65,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
    "                        [ 0.65,    1,    0,    0,    0,    0,    0,    0,    0, 0.12,    0,    0],\n",
    "                        [    0,    0,    1, 0.12,-0.18, 0.13,    0,    0,    0,-0.22,    0,    0],\n",
    "                        [    0,    0, 0.12,    1, 0.54, 0.71,-0.14,    0,    0,    0,    0,    0],\n",
    "                        [    0,    0,-0.18, 0.54,    1, 0.34, 0.20, 0.11,    0, 0.38,    0,    0],\n",
    "                        [    0,    0, 0.13, 0.71, 0.34,    1,-0.11,    0,    0,-0.13,    0,    0],\n",
    "                        [    0,    0,    0,-0.14, 0.20,-0.11,    1,    0,-0.69,-0.39,-0.19,    0],\n",
    "                        [    0,    0,    0,    0, 0.11,    0,    0,    1,-0.34,    0,    0,    0],\n",
    "                        [    0,    0,    0,    0,    0,    0,-0.69,-0.34,    1, 0.41, 0.40,    0],\n",
    "                        [    0, 0.12,-0.22,    0, 0.38,-0.13,-0.39,    0, 0.41,    1, 0.14,    0],\n",
    "                        [    0,    0,    0,    0,    0,    0,-0.19,    0,  0.4, 0.14,    1,    0],\n",
    "                        [    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    1]])\n",
    "\n",
    "my_num_dir_samples = 10\n",
    "\n",
    "my_delta_h = 0.1\n",
    "# my_delta_h = 1 / my_num_dir_samples # or choose values such as 0.1\n",
    "\n",
    "experiment_3 = GVARS(parameters     = my_parameters,\n",
    "                    corr_mat        = my_corr_mat,\n",
    "                    num_stars       = 10,\n",
    "                    num_dir_samples = my_num_dir_samples,\n",
    "                    delta_h         = my_delta_h,\n",
    "                    ivars_scales    = (0.1, 0.3, 0.5),\n",
    "                    model           = HBV_model,\n",
    "                    seed            = 123456789,\n",
    "                    bootstrap_flag  = False,\n",
    "                    bootstrap_size  = 100,\n",
    "                    bootstrap_ci    = 0.9,\n",
    "                    grouping_flag   = False,\n",
    "                    num_grps        = 3,\n",
    "                    report_verbose  = True,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run STAR-GVARS\n",
    "\n",
    "Now, run the GVARS experiment set up above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f77de9f72f64af38554930fe5b235ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='generating star points\\n (note: first step will take awhile as the fictive matrix i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment_3.run_online()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check out the results\n",
    "\n",
    "When the GVARS analysis is completed, let's check out the results of sensitivity analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IVARS: Integrated variogram Across a Range of Scales** \n",
    "\n",
    "IVARS indices are the primary sensitivity indices by the VARS approach. First, print all the IVARS indices for the scale ranges of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = experiment_3.parameters.keys()\n",
    "experiment_3.ivars[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Choose a scale range and plot the respective IVARS indices. Two points:\n",
    " \n",
    "    POINT1: VARS-50 (h=[0-0.5]), called ***Total-Variogram Effect*** is the most comprehensive sensitivity index.\n",
    "    POINT2: Plotting sensitivity results in log scale helps us better differentiate less influential parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ivars_scale = 0.5 # Choose the scale range of interest, e.g., 0.1, 0.3, or 0.5\n",
    "\n",
    "cols = experiment_3.parameters.keys()                     \n",
    "fig_bar = plt.figure(figsize=(10,5))\n",
    "plt.gca().bar(cols, experiment_3.ivars.loc[pd.IndexSlice[ ivars_scale ]][cols], color='gold')\n",
    "plt.gca().set_title (r'Integrated variogram Across a Range of Scales', fontsize = 15)\n",
    "plt.gca().set_ylabel(r'IVARS-50 (Total-Variogram Effect)', fontsize = 13)\n",
    "plt.gca().set_xlabel(r'Model Parameter', fontsize=13)\n",
    "plt.gca().grid()\n",
    "plt.gca().set_yscale('linear')\n",
    "\n",
    "fig_bar = plt.figure(figsize=(10,5))\n",
    "plt.gca().bar(cols, experiment_3.ivars.loc[pd.IndexSlice[ ivars_scale ]][cols], color='gold')\n",
    "plt.gca().set_title (r'Integrated variogram Across a Range of Scales $[log-scale]$', fontsize = 15)\n",
    "plt.gca().set_ylabel(r'IVARS-50 (Total-Variogram Effect)', fontsize = 13)\n",
    "plt.gca().set_xlabel(r'Model Parameter', fontsize=13)\n",
    "plt.gca().grid()\n",
    "plt.gca().set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VARS-TO: Sobol Total-Order Effect** \n",
    "\n",
    "In addition to the IVARS indices, VARS estimates Sobol variance-based total-order effects as side products. Below, print them and plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = experiment_3.parameters.keys()\n",
    "experiment_3.st.to_frame().T[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = experiment_3.parameters.keys()                     \n",
    "fig_bar = plt.figure(figsize=(10,5))\n",
    "plt.gca().bar(cols, experiment_3.st.to_frame().T.iloc[0][cols], color='lightblue')\n",
    "plt.gca().set_title (r'Sobol Total-Order Effect', fontsize = 15)\n",
    "plt.gca().set_ylabel(r'VARS-TO (Total-Order Effect)', fontsize = 13)\n",
    "plt.gca().set_xlabel(r'Model Parameter', fontsize=13)\n",
    "plt.gca().grid()\n",
    "plt.gca().set_yscale('linear')\n",
    "\n",
    "fig_bar = plt.figure(figsize=(10,5))\n",
    "plt.gca().bar(cols, experiment_3.st.to_frame().T.iloc[0][cols], color='lightblue')\n",
    "plt.gca().set_title (r'Sobol Total-Order Effect $[log-scale]$', fontsize = 15)\n",
    "plt.gca().set_ylabel(r'VARS-TO (Total-Order Effect)', fontsize = 13)\n",
    "plt.gca().set_xlabel(r'Model Parameter', fontsize=13)\n",
    "plt.gca().grid()\n",
    "plt.gca().set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VARS-ABE & VARS-ACE: Morris Elementary Effects** \n",
    "\n",
    "In addition to the IVARS and Sobol indices, VARS estimates various versions of Morris derivative-based elementary effects as side products, **mean ABsolute Elementary effect (ABE)** and **mean ACtual elementary effect (ACE)**.\n",
    "\n",
    "    POINT: In the derivative-based approach, the user needs to choose a delta (step size) for numerical estimation of derivatives. Recommended is to go with the smallest delta available here, which is equal to delta_h, but the user could choose any integer product of delta_h as well.\n",
    "\n",
    " Below, print VARS-ABE & VARS-ACE and then plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delta_of_interest = experiment_3.maee.to_frame().unstack(level=0).index.min() # This lines chooses the smallest delta\n",
    "delta_of_interest = 0.1  # This line can be used to set other values for delta\n",
    "\n",
    "# VARS-ABE\n",
    "experiment_3.maee.to_frame().unstack(level=0).loc[delta_of_interest].to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARS-ACE\n",
    "experiment_3.mee.to_frame().unstack(level=0).loc[delta_of_interest].to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = experiment_3.parameters.keys()                     \n",
    "fig_bar = plt.figure(figsize=(10,5))\n",
    "plt.gca().bar(cols, experiment_3.maee.to_frame().unstack(level=0).loc[delta_of_interest].to_frame().T.iloc[0], color='green')\n",
    "plt.gca().set_title (r'Mean Absolute Elementary Effect', fontsize = 15)\n",
    "plt.gca().set_ylabel(r'VARS-ABE', fontsize = 13)\n",
    "plt.gca().set_xlabel(r'Model Parameter', fontsize=13)\n",
    "plt.gca().grid()\n",
    "plt.gca().set_yscale('linear')\n",
    "\n",
    "fig_bar = plt.figure(figsize=(10,5))\n",
    "plt.gca().bar(cols, experiment_3.mee.to_frame().unstack(level=0).loc[delta_of_interest].to_frame().T.iloc[0], color='lightgreen')\n",
    "plt.gca().set_title (r'Mean Actual Elementary Effect ', fontsize = 15)\n",
    "plt.gca().set_ylabel(r'VARS-ACE', fontsize = 13)\n",
    "plt.gca().set_xlabel(r'Model Parameter', fontsize=13)\n",
    "plt.gca().grid()\n",
    "plt.gca().set_yscale('linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Directional Variograms - γ(h)** \n",
    "\n",
    "For advanced users of VARS, directional variograms may provide a wealth of information about the structure of the model response surface.\n",
    "\n",
    "    POINT: Variograms are most meaningful when h (perturbation scale) is between zero and 0.5 of the parameter ranges, but the user can investigate the entire perturbation range (0 – 1).\n",
    "    \n",
    " Below, print the directional variograms and then plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = experiment_3.parameters.keys()                     \n",
    "variograms = experiment_3.gamma.unstack(0)[cols].copy()\n",
    "variograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_scale = 0.5 # any number between delta_h and one.\n",
    "\n",
    "matrix_y = variograms.loc[variograms.index <= plotting_scale].to_numpy()\n",
    "column_x = variograms.loc[variograms.index <= plotting_scale].index.to_numpy()\n",
    "matrix_x = np.tile(column_x, (matrix_y.shape[1], 1)).T\n",
    "\n",
    "fig_cdf = plt.figure(figsize=(10,5))\n",
    "plt.gca().plot(matrix_x, matrix_y )\n",
    "plt.gca().set_title (r'Directional Variogram', fontsize = 15)\n",
    "plt.gca().set_ylabel(r'$γ(h)$', fontsize = 13)\n",
    "plt.gca().set_xlabel(r'$h$ (perturbation scale)', fontsize=13)\n",
    "plt.gca().set_yscale('linear')\n",
    "plt.gca().legend (cols, loc='upper left', fontsize = 10)\n",
    "plt.gca().grid()\n",
    "\n",
    "fig_cdf = plt.figure(figsize=(10,5))\n",
    "plt.gca().plot(matrix_x, matrix_y )\n",
    "plt.gca().set_title (r'Directional Variogram $[log-scale]$', fontsize = 15)\n",
    "plt.gca().set_ylabel(r'$γ(h)$', fontsize = 13)\n",
    "plt.gca().set_xlabel(r'$h$ (perturbation scale)', fontsize=13)\n",
    "plt.gca().set_yscale('log')\n",
    "plt.gca().legend (cols, loc='lower right', fontsize = 10)\n",
    "plt.gca().grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional information for advanced users\n",
    "\n",
    "The information below are also available to the user, if there is interest in further exploring what is happening under the hood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The fictive correlation matrix**\n",
    "\n",
    "The fictive correlation matrix is a transformation of the original correlation matrix to a normal standard space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fictive_matrix = experiment_3.cov_mat\n",
    "cols = experiment_3.parameters.keys()\n",
    "pd.DataFrame(data = fictive_matrix, index = cols, columns = cols).round(decimals=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross sections of sample points in the model parameter space**\n",
    "\n",
    "Choose any pair of parameters and see the projection of all star centers and star points onto their two-dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['FRAC', 'beta']\n",
    "experiment_3.correlation_plot(param_names=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Star centers used in the GVARS experiment**\n",
    "\n",
    "The following dataframe includes all the star centers generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = experiment_3.parameters.keys()\n",
    "pd.DataFrame(data=experiment_3.star_centres, columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Star points generated in the GVARS experiment along with respective model responses**\n",
    "\n",
    "The following dataframe includes all the star points generated. For each row, the first column indicates the associated star center, the second column indicates the parameter along which the cross-sectional samples were taken, and the third column indicates the star point numbers along that cross section. The last column indicates the evaluated model response for the parameter set in each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = experiment_3.parameters.keys()\n",
    "star_points = experiment_3.model_df.copy()\n",
    "cols = list(cols)\n",
    "cols.append(star_points.columns[-1])\n",
    "star_points.columns = cols\n",
    "star_points\n",
    "# experiment_3.star_points  # this dataframe only includes star points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pairs generated in the GVARS experiment using all the star points**\n",
    "\n",
    "Each row represents the information for a pair of sample points. For each pair, the first column indicates the associated star center, the second column indicates the parameter along which the points in the pair are aligned, the third column  indicates the representative bin size (in terms of h) used in the estimation of directional variograms, the fourth column indicates the actual h value for that pair (used in binning), the fifth column indicates the star point numbers forming that pair, the sixth and seventh columns are the model responses for the two star points in the pair, and the last column (dissimilarity) is the squared difference between the two model responses in a pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_3.pair_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
